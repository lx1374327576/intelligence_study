{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.357349\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *Fill this in*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -0.850911 analytic: -0.850911, relative error: 6.021567e-09\n",
      "numerical: -0.957899 analytic: -0.957899, relative error: 5.319258e-08\n",
      "numerical: -1.636767 analytic: -1.636767, relative error: 2.757683e-08\n",
      "numerical: 0.605039 analytic: 0.605039, relative error: 1.044790e-08\n",
      "numerical: 0.604681 analytic: 0.604681, relative error: 2.211139e-08\n",
      "numerical: 0.384364 analytic: 0.384364, relative error: 6.797931e-08\n",
      "numerical: 1.051191 analytic: 1.051192, relative error: 4.784861e-08\n",
      "numerical: -0.747514 analytic: -0.747514, relative error: 2.895834e-08\n",
      "numerical: -0.128812 analytic: -0.128812, relative error: 1.083591e-07\n",
      "numerical: -3.612155 analytic: -3.612155, relative error: 1.036147e-08\n",
      "numerical: 1.765656 analytic: 1.760664, relative error: 1.415663e-03\n",
      "numerical: 2.372965 analytic: 2.373785, relative error: 1.726511e-04\n",
      "numerical: -0.549670 analytic: -0.546852, relative error: 2.570421e-03\n",
      "numerical: 0.368805 analytic: 0.343312, relative error: 3.579955e-02\n",
      "numerical: 0.018398 analytic: 0.022445, relative error: 9.910043e-02\n",
      "numerical: 1.206136 analytic: 1.199216, relative error: 2.876826e-03\n",
      "numerical: -0.024678 analytic: -0.024581, relative error: 1.962357e-03\n",
      "numerical: 2.920726 analytic: 2.908561, relative error: 2.086820e-03\n",
      "numerical: -0.609986 analytic: -0.612861, relative error: 2.350749e-03\n",
      "numerical: 1.152075 analytic: 1.147652, relative error: 1.923289e-03\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.357349e+00 computed in 0.069313s\n",
      "vectorized loss: 2.357349e+00 computed in 0.005933s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 765.956891\n",
      "iteration 100 / 1500: loss 462.661955\n",
      "iteration 200 / 1500: loss 280.737291\n",
      "iteration 300 / 1500: loss 170.449652\n",
      "iteration 400 / 1500: loss 103.928595\n",
      "iteration 500 / 1500: loss 63.792198\n",
      "iteration 600 / 1500: loss 39.354534\n",
      "iteration 700 / 1500: loss 24.603333\n",
      "iteration 800 / 1500: loss 15.773496\n",
      "iteration 900 / 1500: loss 10.385164\n",
      "iteration 1000 / 1500: loss 7.187654\n",
      "iteration 1100 / 1500: loss 5.146936\n",
      "iteration 1200 / 1500: loss 3.960492\n",
      "iteration 1300 / 1500: loss 3.193905\n",
      "iteration 1400 / 1500: loss 2.778318\n",
      "iteration 0 / 1500: loss 924.395878\n",
      "iteration 100 / 1500: loss 505.699661\n",
      "iteration 200 / 1500: loss 277.555198\n",
      "iteration 300 / 1500: loss 152.800376\n",
      "iteration 400 / 1500: loss 84.542833\n",
      "iteration 500 / 1500: loss 47.237736\n",
      "iteration 600 / 1500: loss 26.796174\n",
      "iteration 700 / 1500: loss 15.663317\n",
      "iteration 800 / 1500: loss 9.449287\n",
      "iteration 900 / 1500: loss 6.141183\n",
      "iteration 1000 / 1500: loss 4.279403\n",
      "iteration 1100 / 1500: loss 3.359270\n",
      "iteration 1200 / 1500: loss 2.772398\n",
      "iteration 1300 / 1500: loss 2.436318\n",
      "iteration 1400 / 1500: loss 2.326581\n",
      "iteration 0 / 1500: loss 1073.421696\n",
      "iteration 100 / 1500: loss 531.575174\n",
      "iteration 200 / 1500: loss 264.013910\n",
      "iteration 300 / 1500: loss 131.762211\n",
      "iteration 400 / 1500: loss 66.329244\n",
      "iteration 500 / 1500: loss 33.909580\n",
      "iteration 600 / 1500: loss 17.754992\n",
      "iteration 700 / 1500: loss 9.960651\n",
      "iteration 800 / 1500: loss 6.040933\n",
      "iteration 900 / 1500: loss 4.032713\n",
      "iteration 1000 / 1500: loss 3.167803\n",
      "iteration 1100 / 1500: loss 2.617798\n",
      "iteration 1200 / 1500: loss 2.452053\n",
      "iteration 1300 / 1500: loss 2.270798\n",
      "iteration 1400 / 1500: loss 2.170018\n",
      "iteration 0 / 1500: loss 1244.964541\n",
      "iteration 100 / 1500: loss 557.674355\n",
      "iteration 200 / 1500: loss 250.733850\n",
      "iteration 300 / 1500: loss 113.353048\n",
      "iteration 400 / 1500: loss 51.950753\n",
      "iteration 500 / 1500: loss 24.456192\n",
      "iteration 600 / 1500: loss 12.132050\n",
      "iteration 700 / 1500: loss 6.591031\n",
      "iteration 800 / 1500: loss 4.141418\n",
      "iteration 900 / 1500: loss 3.067493\n",
      "iteration 1000 / 1500: loss 2.506655\n",
      "iteration 1100 / 1500: loss 2.330760\n",
      "iteration 1200 / 1500: loss 2.255781\n",
      "iteration 1300 / 1500: loss 2.184371\n",
      "iteration 1400 / 1500: loss 2.186143\n",
      "iteration 0 / 1500: loss 1387.312198\n",
      "iteration 100 / 1500: loss 562.234599\n",
      "iteration 200 / 1500: loss 228.767591\n",
      "iteration 300 / 1500: loss 93.882934\n",
      "iteration 400 / 1500: loss 39.274618\n",
      "iteration 500 / 1500: loss 17.193280\n",
      "iteration 600 / 1500: loss 8.283620\n",
      "iteration 700 / 1500: loss 4.597508\n",
      "iteration 800 / 1500: loss 3.127247\n",
      "iteration 900 / 1500: loss 2.618308\n",
      "iteration 1000 / 1500: loss 2.363923\n",
      "iteration 1100 / 1500: loss 2.267235\n",
      "iteration 1200 / 1500: loss 2.205721\n",
      "iteration 1300 / 1500: loss 2.204077\n",
      "iteration 1400 / 1500: loss 2.132625\n",
      "iteration 0 / 1500: loss 778.577842\n",
      "iteration 100 / 1500: loss 315.395057\n",
      "iteration 200 / 1500: loss 128.616407\n",
      "iteration 300 / 1500: loss 53.287488\n",
      "iteration 400 / 1500: loss 22.858367\n",
      "iteration 500 / 1500: loss 10.432414\n",
      "iteration 600 / 1500: loss 5.536528\n",
      "iteration 700 / 1500: loss 3.445105\n",
      "iteration 800 / 1500: loss 2.717386\n",
      "iteration 900 / 1500: loss 2.356251\n",
      "iteration 1000 / 1500: loss 2.156546\n",
      "iteration 1100 / 1500: loss 2.176392\n",
      "iteration 1200 / 1500: loss 2.119960\n",
      "iteration 1300 / 1500: loss 2.178867\n",
      "iteration 1400 / 1500: loss 2.110878\n",
      "iteration 0 / 1500: loss 933.906448\n",
      "iteration 100 / 1500: loss 315.756432\n",
      "iteration 200 / 1500: loss 107.768191\n",
      "iteration 300 / 1500: loss 37.776344\n",
      "iteration 400 / 1500: loss 14.163294\n",
      "iteration 500 / 1500: loss 6.211843\n",
      "iteration 600 / 1500: loss 3.480524\n",
      "iteration 700 / 1500: loss 2.649206\n",
      "iteration 800 / 1500: loss 2.219414\n",
      "iteration 900 / 1500: loss 2.112261\n",
      "iteration 1000 / 1500: loss 2.233001\n",
      "iteration 1100 / 1500: loss 2.128227\n",
      "iteration 1200 / 1500: loss 2.206606\n",
      "iteration 1300 / 1500: loss 2.102306\n",
      "iteration 1400 / 1500: loss 2.113301\n",
      "iteration 0 / 1500: loss 1085.512224\n",
      "iteration 100 / 1500: loss 306.303847\n",
      "iteration 200 / 1500: loss 87.675710\n",
      "iteration 300 / 1500: loss 26.305769\n",
      "iteration 400 / 1500: loss 8.966416\n",
      "iteration 500 / 1500: loss 3.996631\n",
      "iteration 600 / 1500: loss 2.723129\n",
      "iteration 700 / 1500: loss 2.293494\n",
      "iteration 800 / 1500: loss 2.192355\n",
      "iteration 900 / 1500: loss 2.061654\n",
      "iteration 1000 / 1500: loss 2.181626\n",
      "iteration 1100 / 1500: loss 2.159585\n",
      "iteration 1200 / 1500: loss 2.098090\n",
      "iteration 1300 / 1500: loss 2.195755\n",
      "iteration 1400 / 1500: loss 2.116479\n",
      "iteration 0 / 1500: loss 1232.049864\n",
      "iteration 100 / 1500: loss 290.248023\n",
      "iteration 200 / 1500: loss 69.775439\n",
      "iteration 300 / 1500: loss 18.056126\n",
      "iteration 400 / 1500: loss 5.872785\n",
      "iteration 500 / 1500: loss 3.061193\n",
      "iteration 600 / 1500: loss 2.323019\n",
      "iteration 700 / 1500: loss 2.164250\n",
      "iteration 800 / 1500: loss 2.111750\n",
      "iteration 900 / 1500: loss 2.166570\n",
      "iteration 1000 / 1500: loss 2.106451\n",
      "iteration 1100 / 1500: loss 2.174710\n",
      "iteration 1200 / 1500: loss 2.157492\n",
      "iteration 1300 / 1500: loss 2.133336\n",
      "iteration 1400 / 1500: loss 2.166635\n",
      "iteration 0 / 1500: loss 1371.641611\n",
      "iteration 100 / 1500: loss 269.980785\n",
      "iteration 200 / 1500: loss 54.592777\n",
      "iteration 300 / 1500: loss 12.444564\n",
      "iteration 400 / 1500: loss 4.144203\n",
      "iteration 500 / 1500: loss 2.521469\n",
      "iteration 600 / 1500: loss 2.265195\n",
      "iteration 700 / 1500: loss 2.238034\n",
      "iteration 800 / 1500: loss 2.116879\n",
      "iteration 900 / 1500: loss 2.078500\n",
      "iteration 1000 / 1500: loss 2.138356\n",
      "iteration 1100 / 1500: loss 2.160189\n",
      "iteration 1200 / 1500: loss 2.120100\n",
      "iteration 1300 / 1500: loss 2.139022\n",
      "iteration 1400 / 1500: loss 2.146545\n",
      "iteration 0 / 1500: loss 767.144867\n",
      "iteration 100 / 1500: loss 207.968869\n",
      "iteration 200 / 1500: loss 57.707994\n",
      "iteration 300 / 1500: loss 17.129786\n",
      "iteration 400 / 1500: loss 6.150084\n",
      "iteration 500 / 1500: loss 3.217328\n",
      "iteration 600 / 1500: loss 2.401914\n",
      "iteration 700 / 1500: loss 2.166101\n",
      "iteration 800 / 1500: loss 2.145080\n",
      "iteration 900 / 1500: loss 2.076552\n",
      "iteration 1000 / 1500: loss 2.138590\n",
      "iteration 1100 / 1500: loss 2.183251\n",
      "iteration 1200 / 1500: loss 2.074697\n",
      "iteration 1300 / 1500: loss 2.123062\n",
      "iteration 1400 / 1500: loss 2.083152\n",
      "iteration 0 / 1500: loss 923.182263\n",
      "iteration 100 / 1500: loss 192.942381\n",
      "iteration 200 / 1500: loss 41.759601\n",
      "iteration 300 / 1500: loss 10.383715\n",
      "iteration 400 / 1500: loss 3.829686\n",
      "iteration 500 / 1500: loss 2.514796\n",
      "iteration 600 / 1500: loss 2.192666\n",
      "iteration 700 / 1500: loss 2.151644\n",
      "iteration 800 / 1500: loss 2.125049\n",
      "iteration 900 / 1500: loss 2.187742\n",
      "iteration 1000 / 1500: loss 2.160366\n",
      "iteration 1100 / 1500: loss 2.103713\n",
      "iteration 1200 / 1500: loss 2.206991\n",
      "iteration 1300 / 1500: loss 2.057893\n",
      "iteration 1400 / 1500: loss 2.103084\n",
      "iteration 0 / 1500: loss 1082.295602\n",
      "iteration 100 / 1500: loss 174.283656\n",
      "iteration 200 / 1500: loss 29.664043\n",
      "iteration 300 / 1500: loss 6.552496\n",
      "iteration 400 / 1500: loss 2.746864\n",
      "iteration 500 / 1500: loss 2.282601\n",
      "iteration 600 / 1500: loss 2.183550\n",
      "iteration 700 / 1500: loss 2.110378\n",
      "iteration 800 / 1500: loss 2.141892\n",
      "iteration 900 / 1500: loss 2.119238\n",
      "iteration 1000 / 1500: loss 2.089759\n",
      "iteration 1100 / 1500: loss 2.162251\n",
      "iteration 1200 / 1500: loss 2.114647\n",
      "iteration 1300 / 1500: loss 2.152675\n",
      "iteration 1400 / 1500: loss 2.135684\n",
      "iteration 0 / 1500: loss 1242.819993\n",
      "iteration 100 / 1500: loss 154.184643\n",
      "iteration 200 / 1500: loss 20.911391\n",
      "iteration 300 / 1500: loss 4.471660\n",
      "iteration 400 / 1500: loss 2.399023\n",
      "iteration 500 / 1500: loss 2.225891\n",
      "iteration 600 / 1500: loss 2.149666\n",
      "iteration 700 / 1500: loss 2.188694\n",
      "iteration 800 / 1500: loss 2.140527\n",
      "iteration 900 / 1500: loss 2.160894\n",
      "iteration 1000 / 1500: loss 2.121280\n",
      "iteration 1100 / 1500: loss 2.132372\n",
      "iteration 1200 / 1500: loss 2.178699\n",
      "iteration 1300 / 1500: loss 2.177698\n",
      "iteration 1400 / 1500: loss 2.139034\n",
      "iteration 0 / 1500: loss 1402.348924\n",
      "iteration 100 / 1500: loss 134.134200\n",
      "iteration 200 / 1500: loss 14.680061\n",
      "iteration 300 / 1500: loss 3.341497\n",
      "iteration 400 / 1500: loss 2.253213\n",
      "iteration 500 / 1500: loss 2.169161\n",
      "iteration 600 / 1500: loss 2.187371\n",
      "iteration 700 / 1500: loss 2.208850\n",
      "iteration 800 / 1500: loss 2.187578\n",
      "iteration 900 / 1500: loss 2.140632\n",
      "iteration 1000 / 1500: loss 2.160136\n",
      "iteration 1100 / 1500: loss 2.206141\n",
      "iteration 1200 / 1500: loss 2.162627\n",
      "iteration 1300 / 1500: loss 2.136837\n",
      "iteration 1400 / 1500: loss 2.120991\n",
      "iteration 0 / 1500: loss 770.749466\n",
      "iteration 100 / 1500: loss 139.787460\n",
      "iteration 200 / 1500: loss 26.908033\n",
      "iteration 300 / 1500: loss 6.613628\n",
      "iteration 400 / 1500: loss 2.938050\n",
      "iteration 500 / 1500: loss 2.267537\n",
      "iteration 600 / 1500: loss 2.083347\n",
      "iteration 700 / 1500: loss 2.092981\n",
      "iteration 800 / 1500: loss 2.125095\n",
      "iteration 900 / 1500: loss 2.114058\n",
      "iteration 1000 / 1500: loss 2.111916\n",
      "iteration 1100 / 1500: loss 2.164863\n",
      "iteration 1200 / 1500: loss 2.115143\n",
      "iteration 1300 / 1500: loss 2.139824\n",
      "iteration 1400 / 1500: loss 2.161237\n",
      "iteration 0 / 1500: loss 922.352593\n",
      "iteration 100 / 1500: loss 119.246295\n",
      "iteration 200 / 1500: loss 17.109245\n",
      "iteration 300 / 1500: loss 4.135524\n",
      "iteration 400 / 1500: loss 2.359933\n",
      "iteration 500 / 1500: loss 2.204707\n",
      "iteration 600 / 1500: loss 2.140127\n",
      "iteration 700 / 1500: loss 2.149517\n",
      "iteration 800 / 1500: loss 2.072487\n",
      "iteration 900 / 1500: loss 2.129291\n",
      "iteration 1000 / 1500: loss 2.097326\n",
      "iteration 1100 / 1500: loss 2.128955\n",
      "iteration 1200 / 1500: loss 2.131678\n",
      "iteration 1300 / 1500: loss 2.136995\n",
      "iteration 1400 / 1500: loss 2.100408\n",
      "iteration 0 / 1500: loss 1076.231545\n",
      "iteration 100 / 1500: loss 99.133619\n",
      "iteration 200 / 1500: loss 11.025891\n",
      "iteration 300 / 1500: loss 2.868481\n",
      "iteration 400 / 1500: loss 2.214330\n",
      "iteration 500 / 1500: loss 2.132728\n",
      "iteration 600 / 1500: loss 2.123596\n",
      "iteration 700 / 1500: loss 2.149756\n",
      "iteration 800 / 1500: loss 2.169455\n",
      "iteration 900 / 1500: loss 2.152622\n",
      "iteration 1000 / 1500: loss 2.153020\n",
      "iteration 1100 / 1500: loss 2.178341\n",
      "iteration 1200 / 1500: loss 2.163353\n",
      "iteration 1300 / 1500: loss 2.139352\n",
      "iteration 1400 / 1500: loss 2.179606\n",
      "iteration 0 / 1500: loss 1230.398936\n",
      "iteration 100 / 1500: loss 80.877996\n",
      "iteration 200 / 1500: loss 7.202172\n",
      "iteration 300 / 1500: loss 2.434392\n",
      "iteration 400 / 1500: loss 2.153220\n",
      "iteration 500 / 1500: loss 2.156105\n",
      "iteration 600 / 1500: loss 2.146532\n",
      "iteration 700 / 1500: loss 2.201726\n",
      "iteration 800 / 1500: loss 2.178786\n",
      "iteration 900 / 1500: loss 2.174744\n",
      "iteration 1000 / 1500: loss 2.168803\n",
      "iteration 1100 / 1500: loss 2.158359\n",
      "iteration 1200 / 1500: loss 2.151181\n",
      "iteration 1300 / 1500: loss 2.123935\n",
      "iteration 1400 / 1500: loss 2.220778\n",
      "iteration 0 / 1500: loss 1382.859910\n",
      "iteration 100 / 1500: loss 64.719366\n",
      "iteration 200 / 1500: loss 5.001960\n",
      "iteration 300 / 1500: loss 2.303412\n",
      "iteration 400 / 1500: loss 2.193758\n",
      "iteration 500 / 1500: loss 2.184981\n",
      "iteration 600 / 1500: loss 2.150671\n",
      "iteration 700 / 1500: loss 2.128755\n",
      "iteration 800 / 1500: loss 2.176122\n",
      "iteration 900 / 1500: loss 2.167216\n",
      "iteration 1000 / 1500: loss 2.245171\n",
      "iteration 1100 / 1500: loss 2.197398\n",
      "iteration 1200 / 1500: loss 2.153100\n",
      "iteration 1300 / 1500: loss 2.139180\n",
      "iteration 1400 / 1500: loss 2.168718\n",
      "iteration 0 / 1500: loss 776.738051\n",
      "iteration 100 / 1500: loss 94.739565\n",
      "iteration 200 / 1500: loss 13.278938\n",
      "iteration 300 / 1500: loss 3.496959\n",
      "iteration 400 / 1500: loss 2.216586\n",
      "iteration 500 / 1500: loss 2.030848\n",
      "iteration 600 / 1500: loss 2.138599\n",
      "iteration 700 / 1500: loss 2.151271\n",
      "iteration 800 / 1500: loss 2.102381\n",
      "iteration 900 / 1500: loss 2.175236\n",
      "iteration 1000 / 1500: loss 2.145471\n",
      "iteration 1100 / 1500: loss 2.218559\n",
      "iteration 1200 / 1500: loss 2.134450\n",
      "iteration 1300 / 1500: loss 2.117464\n",
      "iteration 1400 / 1500: loss 2.114571\n",
      "iteration 0 / 1500: loss 924.120843\n",
      "iteration 100 / 1500: loss 74.344345\n",
      "iteration 200 / 1500: loss 7.819408\n",
      "iteration 300 / 1500: loss 2.596863\n",
      "iteration 400 / 1500: loss 2.170251\n",
      "iteration 500 / 1500: loss 2.148565\n",
      "iteration 600 / 1500: loss 2.141497\n",
      "iteration 700 / 1500: loss 2.116586\n",
      "iteration 800 / 1500: loss 2.140904\n",
      "iteration 900 / 1500: loss 2.123935\n",
      "iteration 1000 / 1500: loss 2.075149\n",
      "iteration 1100 / 1500: loss 2.190012\n",
      "iteration 1200 / 1500: loss 2.117316\n",
      "iteration 1300 / 1500: loss 2.145346\n",
      "iteration 1400 / 1500: loss 2.113088\n",
      "iteration 0 / 1500: loss 1085.900881\n",
      "iteration 100 / 1500: loss 57.484081\n",
      "iteration 200 / 1500: loss 5.034010\n",
      "iteration 300 / 1500: loss 2.289433\n",
      "iteration 400 / 1500: loss 2.142758\n",
      "iteration 500 / 1500: loss 2.160623\n",
      "iteration 600 / 1500: loss 2.158388\n",
      "iteration 700 / 1500: loss 2.095280\n",
      "iteration 800 / 1500: loss 2.176783\n",
      "iteration 900 / 1500: loss 2.173537\n",
      "iteration 1000 / 1500: loss 2.147606\n",
      "iteration 1100 / 1500: loss 2.146603\n",
      "iteration 1200 / 1500: loss 2.176195\n",
      "iteration 1300 / 1500: loss 2.174565\n",
      "iteration 1400 / 1500: loss 2.093216\n",
      "iteration 0 / 1500: loss 1242.050291\n",
      "iteration 100 / 1500: loss 43.599568\n",
      "iteration 200 / 1500: loss 3.490248\n",
      "iteration 300 / 1500: loss 2.125902\n",
      "iteration 400 / 1500: loss 2.163853\n",
      "iteration 500 / 1500: loss 2.162407\n",
      "iteration 600 / 1500: loss 2.239126\n",
      "iteration 700 / 1500: loss 2.154956\n",
      "iteration 800 / 1500: loss 2.188852\n",
      "iteration 900 / 1500: loss 2.198892\n",
      "iteration 1000 / 1500: loss 2.116941\n",
      "iteration 1100 / 1500: loss 2.161688\n",
      "iteration 1200 / 1500: loss 2.138161\n",
      "iteration 1300 / 1500: loss 2.156920\n",
      "iteration 1400 / 1500: loss 2.146937\n",
      "iteration 0 / 1500: loss 1385.189743\n",
      "iteration 100 / 1500: loss 32.228873\n",
      "iteration 200 / 1500: loss 2.800623\n",
      "iteration 300 / 1500: loss 2.104346\n",
      "iteration 400 / 1500: loss 2.263093\n",
      "iteration 500 / 1500: loss 2.234544\n",
      "iteration 600 / 1500: loss 2.152399\n",
      "iteration 700 / 1500: loss 2.198136\n",
      "iteration 800 / 1500: loss 2.188613\n",
      "iteration 900 / 1500: loss 2.145943\n",
      "iteration 1000 / 1500: loss 2.168888\n",
      "iteration 1100 / 1500: loss 2.149282\n",
      "iteration 1200 / 1500: loss 2.126975\n",
      "iteration 1300 / 1500: loss 2.221248\n",
      "iteration 1400 / 1500: loss 2.173215\n",
      "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.350673 val accuracy: 0.361000\n",
      "lr 1.000000e-07 reg 3.000000e+04 train accuracy: 0.344286 val accuracy: 0.365000\n",
      "lr 1.000000e-07 reg 3.500000e+04 train accuracy: 0.339000 val accuracy: 0.351000\n",
      "lr 1.000000e-07 reg 4.000000e+04 train accuracy: 0.334000 val accuracy: 0.350000\n",
      "lr 1.000000e-07 reg 4.500000e+04 train accuracy: 0.332816 val accuracy: 0.352000\n",
      "lr 1.800000e-07 reg 2.500000e+04 train accuracy: 0.347796 val accuracy: 0.362000\n",
      "lr 1.800000e-07 reg 3.000000e+04 train accuracy: 0.345837 val accuracy: 0.359000\n",
      "lr 1.800000e-07 reg 3.500000e+04 train accuracy: 0.341531 val accuracy: 0.354000\n",
      "lr 1.800000e-07 reg 4.000000e+04 train accuracy: 0.337531 val accuracy: 0.345000\n",
      "lr 1.800000e-07 reg 4.500000e+04 train accuracy: 0.333367 val accuracy: 0.347000\n",
      "lr 2.600000e-07 reg 2.500000e+04 train accuracy: 0.346469 val accuracy: 0.365000\n",
      "lr 2.600000e-07 reg 3.000000e+04 train accuracy: 0.343347 val accuracy: 0.363000\n",
      "lr 2.600000e-07 reg 3.500000e+04 train accuracy: 0.341204 val accuracy: 0.355000\n",
      "lr 2.600000e-07 reg 4.000000e+04 train accuracy: 0.330469 val accuracy: 0.344000\n",
      "lr 2.600000e-07 reg 4.500000e+04 train accuracy: 0.330041 val accuracy: 0.345000\n",
      "lr 3.400000e-07 reg 2.500000e+04 train accuracy: 0.345163 val accuracy: 0.366000\n",
      "lr 3.400000e-07 reg 3.000000e+04 train accuracy: 0.340163 val accuracy: 0.356000\n",
      "lr 3.400000e-07 reg 3.500000e+04 train accuracy: 0.339184 val accuracy: 0.349000\n",
      "lr 3.400000e-07 reg 4.000000e+04 train accuracy: 0.334184 val accuracy: 0.348000\n",
      "lr 3.400000e-07 reg 4.500000e+04 train accuracy: 0.321224 val accuracy: 0.346000\n",
      "lr 4.200000e-07 reg 2.500000e+04 train accuracy: 0.349898 val accuracy: 0.362000\n",
      "lr 4.200000e-07 reg 3.000000e+04 train accuracy: 0.343163 val accuracy: 0.355000\n",
      "lr 4.200000e-07 reg 3.500000e+04 train accuracy: 0.331755 val accuracy: 0.344000\n",
      "lr 4.200000e-07 reg 4.000000e+04 train accuracy: 0.337571 val accuracy: 0.348000\n",
      "lr 4.200000e-07 reg 4.500000e+04 train accuracy: 0.327449 val accuracy: 0.346000\n",
      "best validation accuracy achieved during cross-validation: 0.366000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "num = 5;\n",
    "for i in range(num):\n",
    "    for j in range(num):\n",
    "        lr = learning_rates[0]+(learning_rates[1]-learning_rates[0])/num*i\n",
    "        reg = regularization_strengths[0]+(regularization_strengths[1]-regularization_strengths[0])/num*j\n",
    "        softmax = Softmax()\n",
    "        softmax.train(X_train, y_train, learning_rate=lr, reg=reg, num_iters=1500, verbose=True)\n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        train_acc = np.mean(y_train == y_train_pred)\n",
    "        val_acc = np.mean(y_val == y_val_pred)\n",
    "        if val_acc > best_val:\n",
    "            best_softmax = softmax\n",
    "            best_val = val_acc\n",
    "        results[(lr, reg)] = (train_acc, val_acc)\n",
    "        # print(i, j)\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.350000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inline Question** - *True or False*\n",
    "\n",
    "It's possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "*Your answer*:\n",
    "\n",
    "*Your explanation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAF8CAYAAADrUz6WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXu0bNlV3jfnflWdc+7tbj0AIyHJMQRiXhE4MpDYFq+A\nJYxRRIyDMVgQkZCAseIREHIUItuAHGIZG4tgm4cZBsTDsoIhZjgMDUiCbGPHPEwMHool1HohMELq\n1r3nnKr9Wvmjqs/6zdKu++hd59xu3e83Ro/et86uXfux1qpV81vfnJ5SMiGEEEII8fgo7vUJCCGE\nEEI8mdFkSgghhBBiBppMCSGEEELMQJMpIYQQQogZaDIlhBBCCDEDTaaEEEIIIWagyZSZuftnuvu7\n7vV5CCEy7v6wu3/uxOt/2N3ffJfH+gF3/5bDnZ0Qwkx96zE0mRJCPKlIKf18Sunj7vV5iKtl3+Ra\niCcCmkwJsQd3r+71OYi7Q89MiCc/T8Z+fF9Npra/bF7h7r/u7u9397/r7suJ/b7J3d/q7je2+/5n\n+NtL3P1N7v5Xt8d4m7u/AH9/0N2/z93f4+7vdvdvcffyqq5RZNz9We7+Bnf/HXf/XXd/rbt/tLv/\n7Pbf73X3H3b3h/Ceh9395e7+q2Z2+mTs1B9iPG+3v+7K8lPPzN0/xd1/aduHf8zMPqifi3vH3fZN\nd/9BM3u2mf2Uu99092+8t1dw/3KrvuXuf8zdf8XdH3H3f+run4y/PcPd/8H2mb/N3b8ef3uVu7/e\n3X/I3T9gZi+50os6APfVZGrLl5nZ55vZR5vZx5rZKyf2eauZ/WEze9DM/qKZ/ZC7fyT+/mlm9mYz\ne7qZfbuZfZ+7+/ZvP2BmvZl9jJl9ipl9npm99OBXIW7JdgL7v5vZ283s95rZM83sR83MzezVZvYM\nM/v9ZvYsM3vVztu/1My+wMweSin1V3PGYg930l/N8MxsM679hJn9oJk91cz+vpl98aWfqbgjHk/f\nTCl9uZm9w8y+MKV0LaX07Vd+4sLcvbE9fcvdP8XMvt/M/msze5qZ/W0z+0l3X7h7YWY/ZWb/yjbP\n+3PM7GXu/vk4/BeZ2ett04d/+Eou6JCklO6b/8zsYTP7Gvz7hbaZOH2mmb3rFu/7FTP7ou32S8zs\nLfjbsZklM/s9ZvYRZrY2syP8/UvN7Ofu9bXfb/+Z2WeY2e+YWXWb/V5kZr+800a+6l6fv/678/66\n+8zM7I+Y2W+ameO1f2pm33Kvr0n/ze6bn3uvz/9+/u9WfcvMvtvM/vLO/m82s+fbJgDxjp2/vcLM\n/u52+1Vm9n/f6+ub89/9KGG8E9tvt82voIC7f4WZ/Xnb/GoyM7tmmyjUY/zWYxsppbNtUOqabWbq\ntZm9JweqrNj5THE1PMvM3p52Ikvu/hFm9jdsE3m8bpvn8/6d9+p5PXG4bX+d2O8ZZvbutB2l8V7x\nxGBO3xT3llv1reeY2Z9x9z+LvzXb9wxm9gx3fwR/K83s5/HvJ/W4ez/KfM/C9rNtM8u+wN2fY2bf\nY2ZfZ2ZPSyk9ZGb/2jYh6NvxTttEpp6eUnpo+98DKaVPOMypi7vgnWb27Ik1T99mm0jiJ6WUHjCz\nP20f/GyTiScKt+yvgM/sPWb2TEjvj71XPDF4vH1T/fLec6u+9U4z+1Z89z2UUjpOKf3I9m9v2/nb\n9ZTSC3GcJ/XzvR8nU1/r7h/l7k81s//BzH5s5+8ntnmov2Nm5u5faWafeCcHTim9x8x+xsxe4+4P\nuHuxXVT5/MOdvrhD/oVtOv5fcfeT7cLl/8Q2v3hvmtmj7v5MM/uGe3mS4rbcrr9O8c9ss27x6929\ndvcXm9kfvMyTFHfF4+2bv21mv+9qT1XscKu+9T1m9jXu/mm+4cTdv8Ddr9vmmd/YGkWO3L109090\n9+fdo+s4OPfjZOp1tpnw/IZt1l+EZGMppV83s9fYptH8tpl9kpn9k7s4/lfYJrT567YJUb/ezD7y\nlu8QByelNJjZF9rGCPAOM3uXmf1J2xgKPtXMHjWzf2Rmb7hX5yjuiFv21ylSSq2Zvdg26xvfZ5vn\nruf8BGFG33y1mb1y6xT776/ujMVj3KpvpZT+pZl9tZm91jbffW/Z7vfYM/9jZvZcM3ubmb3XzL7X\nNiavDwk8Sp8f2rj7w2b20pTSG+/1uQghhBDiQ4P7MTIlhBBCCHEwNJkSQgghhJjBfSXzCSGEEEIc\nGkWmhBBCCCFmcKVJO1/yijdOhsHGcbjYZvqKouBcL78+jGN+b8I2jrMv4OYF0mOM3Clv8xzCcTym\nI+L5DTgWt6syl+VjFLDkofZcMz/ObfpcE66fhyzxuSWO+Xf+0ufcSb6s2/LdL3/ZxUmUuKfOe9Ln\ncytKPEucQeIz4/PwvD8fGY9f1YuL7bppLra7LucCZFvhPWRbMTMbE59BvneF8fW8/zDk4/L6qyp3\nqYRjJjzMrm/zcXCPWmzzaXd9l/dp8/Yr/uZrD/Iszcy+5hs+/eIjF8t8X/kcRtzLff2lH9g2+Tzz\nZon7O2Kfvs/PrcM2+2yJ81ngme+SjP1x+ry5TwrtAe9NeB3Pc0Rb5TXUdX7+PFe+t8T94r37rm97\n00Ge56u/6PMuTmgc8n0cB/Q1jqdoyzX66WKR729V5f3bNdovnndVoQSpcxzIbbbw6THd8Ih4PpuT\nzf9u8Myrmn0N/Rzti+Mvj8PnzX04vrRd3mfAfWQbH3DMFuf9zf/45w7WN1/wZc+7+MDlUe6bi0Xe\nLkq0O9wX29cHMU6x/bLPuoWBF/vk+xLGhLA7ngHbhZm54zNwejxWj7bqoa1yvOiwT2bo+az2zC3w\nhgHfF+vVCueWz+enf/iXb/s8FZkSQgghhJiBJlNCCCGEEDO44tp8iOkxtIjwXlntCycyXElZiZqR\nTe8TZDS8zggwzodS275w/uZkEbrHtlMyQniUMlMVJEKGqKdlvni/KGdOnx+PU/rBIs4XFDgmZRuS\nQlgVoVqG5Pc8m6Kq83H2XBd1t37PcxrDvcVby3jOY0e5eI/ki2ByVefzo4xKibCDJFdCPmkQYl8P\nWTKxfeeKdtO3a7sMyjLLJ0WRr81xrhws2Dd5X5Khz6K7UHYuCsozeZ+qglzGMQH3tIScQek4DVG2\nRRe0voMshb7DsWYIEmN+bptkz4+dN54z+zs+i5JGYdNjE2XhKJ0ehuXiCJ+bPzhcFxoYZfEa59ZQ\nssT1Di3ute+MiRefS0kNfQs3gs+S0l7auScc4sOv/3H6+8Qd/ShRauUxOS5j3MHhmxpyNNpaicvv\ncZ3VHVUcu3v4HDhGhnER11OVuf/yuyWMu8a2zO9cjs35HMIik8Tv0GnJnufjO2MtSzJySQyfeov+\nyGdV4nuhDEsN8nsdbXXscL/4WRwv2H8pke6MKbdDkSkhhBBCiBloMiWEEEIIMYMrlfl6OCISXSbB\nnYfwIML7DAMzbJgQ9hyC3AAQuiz3hH0pC5Q4DsPSQXv5IBh+ZWgV8iFPqZyW8/je4P5DSJz7854O\nCEuGMHZ1+PDz6dn5xXYDaSM6IeHOoGsL4dYaMhLdKdRgo3sTn4Xtfg1HBtxG6zVlMbqudmQ+uvP2\nhMwp1ZW45sUi71PhOtd4NiWD2LwvCGePCH9DXTKj3D1QgjoczWJ5sV3DxcXQe3BkBgdQfpkRfZqy\nKH/ShZm4j1MKZP8oJl8nw440RBmyL/M9S7iiqoEkC4dlsc6OnoGv73EXVxXHrHASeR/03wY3qe8P\n/zwLSLZss0WVX3e2ZfQRynyUI7m0gJLtviUHlEH57Cnhcaxgf6pS/Fqi+6usppcUGMb1uuBYSVcZ\nxvU0LesXPA9KWFB8Cja1nrL25ch8VZOvp0ZbCy5itM2GSyTQTilJjnvGabZrPucxjF/TuqsHKZvO\nznhf0giZv6QbFHJmjWUH/G5F+0kFx2CMWcwOgO+phAFpgPQ/YqxtluibHQfh26PIlBBCCCHEDDSZ\nEkIIIYSYwRW7+abdXR4SOk6HShneLeCkYriSkcg+hJ+nkyFyuwghzczAiOauzEepju8Jic+mPyNI\nJtjueyYJnE64RldCdMHw5GhvOHz4+ez0NP/j+PhikxJRh2tZM5EaLmuN829HuvnyPglz/oGyLtxy\nqy5vr1uEcIPDE6Hw3WeJz6ZsaXD5FUji19SQkfbIOes13HxF3ofunPDIcJy2pdSEa1ud2WVQQ6qk\n1BFuH66N8gElUibCDO2dUg9lAkp41WJy/7KYTkIYXZfxegyOLjqAKPWUNS2T+X5TrqG8TrcSJXXk\nEQyOLo5ZdZOvrQoJEA//ezaNHFsgnVTTn8VEmL4neWkRJJXsFiw897UVpBN24ODQxjhQQoIrF3D2\n9VGy7dHPW0rhe5I5BmmvpouYzwZSWEg8iXO16eUkwUUXvgMuJzZRQ/LivSyMkqdPbjf4rmzoImUS\n4Y5LDdBvKNVCw2MfH4NDfTpBdZQRLdgzwzIKyHwNJWn0rx7j4ojvFybwpcw3MPEq9Fkek8uDKKPe\n7fNUZEoIIYQQYgaaTAkhhBBCzOBKZT4mXGTkLyTiC84w7B8Lz+V9uNKfSR8R6t5fs4/h2hxuZAzQ\n4cjaTfS4Tz5bVHQiZOj6iTWjGKJmeHQ68WhwrlR8hAhXIrzrt3QhPj6CHMlngPMcEYam3NYNdKfh\ndT4bHH+AGNZBvulxfzp8QAfJroNOy0SbTYrPkk6tjnJgg2eG82iDFRShYagQbQ9ZgU4aJrZkHUE4\nEilhdl0Oba/O8/ZBgSxTUZKi84zSVsjICckE7ZduvtKmJXEm8Cxqfi5qsOF5sDYhJe5+x81HGYcy\nVrLpul0Dxgt3SA9wfZbUBoIbCO4hXk9w/027Eyuc56FollmGi8Mda83BneccfyER7UnmGJs+rmuP\nY5da9giNP0hH6Af9jswX6zRi7GciUXwc7+iIY7EN8tpCXTuMp5S1+R0VHHzttDvxkNR02kK25Ni5\nWOSlFlXdTG6PeyT4sA8OyqUydBpzmQkTqvLeheTYO8mueR78GmE7rPEdShde0eR7MVjug9Hxmz97\nscz3pePyD2YHCPVep+cfd4IiU0IIIYQQM9BkSgghhBBiBlcq8zHJ2BBqsuU53QISQzC6ICRcIJzY\nU2JBdJgXFpJZMlldMS0vjqEmIELMO2E/OlwYsnY6IsL+THpIqYtyI2Qpn742uttKuOcoewS35CVE\nnxliHhj2hoONMk8P6Q1KjXWUMhmrh/NixWRrJZ89JCiIR6frvP+6zcdcHue21dTxWTpC1xUSyR03\n+bjLYlryO++mQ+AJ94X7DxY0z3wNK7j/mNwQrSjUXTsgIZEqnVhMvhfa4LREPo6QJykT4HZXqP1X\n8L1B1qYzKL936KZlRMqCZtF5y3p545hD/ednNy+2KflxLLCQ/Bafx6SHRX7+TcN7Ny1tUlaoy8MP\nwQvIfMF1yAS/TJYKaY+JU5slkuhiTOvgnGVCRS/y6yP2oQZH9W/NcYM15HZkPp63lUi6WqA/41zL\nhu5Ntgu0HY6h2KdsKJHR4Yp9OPaNOSnksOtaOxB0rzMBM8ew5RG+N/ck1WSfCG5y0EGGZf069seC\nX0asVxmckNM1/szMlrjHLeo88nuNQySXFIS6t8Hxiz4b5PX8+rqFa5G1a7nd7JPpb48iU0IIIYQQ\nM9BkSgghhBBiBlcq8xUI/RV76lmF+mR0A2GVfUi8xzpMkJJCTaJxeuV+kOkQ2i/pthqmEw+axVBp\nwSRlCI9WdMTgPHrIO3S3WZA/p2tjeajfl9/KkH7I93kJMh9dSD0SW9Yh4eN0ojsm7aSERylhxHHO\nQxJCSA9Vdnaco9mcWd5nhXjx2RpukT7elCI4TvJ5HMGts3AkiUMSzmNKhnhOBZ0qOCaTATaQvDpI\nUAzVUxbzMjpjDkV0s+IZUoZiqJ9RdehfiKSH2lkWjg+pFm5L9hsf8r1YMJknXXGQf+o6DmWUbipI\n5yu6RDFesBnScVbW0783SzgPS9SUrPFZ1LQKtMMy1OU8/O9ZPo9QihTjD5M5+p5UxskphWGc7Zk4\nkzUt86tr1JAcmLAX4x4TXrZMHMnx0OJY1kM+bPB6c5JdW5TqYhLO6Rp8lHxGJpqtWZcTjrdQg5Dn\nfTkyX6yvh3Nlglh8dqhxx23cC0qnVah1i/tSwSHdUyKm7IbvnD2JPQuLz7PG9/cSshqTqrImJh37\nTCoaJOago/P7Pr/M+xjuCxsul3IsJPMJIYQQQlwZmkwJIYQQQszgSmU+Sj0W6iEhnAg3mDPxF5wb\n48jw3rQDKBhCuCqfIc3gyGEisunw9i7jnmsoITlQVqTDJYXaeTw9uiPy63S40G3I5JmxPhUlz51k\nowcg1BqD5FcjeVwKtwfh4JFuKSZ/zKH0M1zLGZ53v4ZEAtfOOuV7foZj3kS4uFshUeHOLan2/K5Y\nINR9BGn6GlQrmAetRpeq2Ai7db4GOFgeOEKCV8h5rGHGCPY4Xo7MR9dLkPxKJn9lQlnWJmQDzu1i\n0fC9kA96OrfYLvJhKowVa9w7JgAMOTQxbpiZDQPHhXxOlBULjCkVpS7IEHTXhmS+TMBb0+nEjJbT\nElg09R5eGiohi5ZIYdmH5Kf5ntKByXMO7mBcQEiCjG0OlRXGwAHjZIsxMCRcxv3s024bn3YD9pTw\nYRFm8mbKP0ze2gQHF/odBgbWDaWsn8JSDNaQi3LWoQjOO7pLOYhRnqTzsKK7FPeFx8e/FqwniWd4\ndp5rgq75XcTafPzOQT+odwZbloikI7HDmJ+Cm5kdBt+zIV81zonJfFm/j/VHuXTE6FrMr47j3T1P\nRaaEEEIIIWagyZQQQgghxAyuVOZjcHEM9dkQomOSzFB7CTXyeriyjpDEEHE/Jjo0JgmkizDUBGQt\nP7rlmCRwx2VCmY8uLoQcG4RZKY2MPu0sYJi9RS2hhFpgwfUEiSVICTh+VR/+MVO2Cc4p1k6inLNG\nTTm6jXCerGV33mF7gDxBJxicLad4NDdXlBXwXpiQooMphqip1CzoPGEiUch/J9jnGD9PlnTb4HpK\nfHYLy98SYfiGoXqnrHI5jqGqoTSAulh0vFJtoKuI8tyC+0Ni6imRTbsZ+YDY1VrUIxx7upCm60Bu\nzhvJQ/tpBxnPzyE30MWT0JfpjOO9GNCv97mFqatQGjE/vDRUNUjaSRdwcEdD5oLkUeKeHCERZKgn\niWvvMF53aAh0wgWn7MDxnfVJWVc0JmDlsgbHZ7D+ItRba+m2Q79e4JwGLr/gWLznO2RE3KGjes9H\nWcXzPhQ15CleM5NNxvqCfJ2SJ5JjL7A/V9/g3o2oY8lahqxLynqVwdSM4zT8Yto5FqVR9u0S59oP\nafJ1XmdwleL4HNcLKvD4LojJrnHEuxxqFZkSQgghhJiBJlNCCCGEEDO42qSdrFXFUB9CxZT5GH4b\nkQSuSkjcyLA9oqwVk4GFKCNcAtV0qDfUFAuugkgIU9NxwjA+pQE6VnA9QdqkhNejBtYQ4pL41Gl5\nijKcXULNKH4W63kVcA8NcAnRXZVQU4+hVCiZoUbU6Xm+3haSmsEJ11IKhLx4hiSB645S7P7QMx1Z\nfMItnxncUIb6fZS5asg8C8TAmVOwhPayQN2xBvXeEhJYVn54Z6ZZrGEWpLCQ3JH9Bf0i8dkyCWc+\nPqWaMA6w3+E6R2gpdPx153D2QYYYd38XwlXIpLjNcZbA2P8HyBIVHYwFxws6ZJGEllqPUfbA/WJS\n35CA9/DuTCY/HIM2iZp1NZ8Trp39C+0g1PjDLj3GQMpf63V+lmsm7WTtUYzRoe7jzj0JOY2ZPBRt\nk9Ijt4MTLnw2E3LWfANOBO5w3Md2mK7xtmQtwwPSLPnc2B8BXa4Fl6lQFqfLE98bTMLJgzIZM24j\nHX/dgHEQ7ahB3/qgPMNo/0wASpmP3ymUoWs6LzFO95wrUM4L+ZTRkApKe3tqaN7l9EiRKSGEEEKI\nGWgyJYQQQggxgyuV+UL9LIeMMVLyy7uExJsMnzMUHbQthORLhg9zKJI1slhiaqCjAZ8a6u8VURqq\nEXI11PBzhFbpVmAEeYEwZpcQEl+dX2xXdCHR3sSkedOlwKxkncLh8I+Z0oAj7t+jlt3Y0UkB52Ti\n84aDrc5OwCNc1zm0wGr5YP6sMicIpZOzx/1p6QJlu9kJPdNht6CrDuHgasiusiOcK/c5gly2hGxH\nJ+CygpznkHKNtfmYVBHXcAkJWM0sxPcTfmPRPcTafGWwxuTNAfLsQJm6Kif3Z1I9huoLdE7WymNt\nttX56eT5m5lVC0j1TDAKV1pzcpLf3kxLOnRMsebZuKcmHRMAxr6JcYCu5stIwsp6dDw3ZjmkLOSQ\n5o119PL2Gs9yzSS6uD8t2vg5jk/3V4E6hh2eGe9n2q3NhxvcLMJajnzeTAyK7wG6VCnJUS6sF7kv\njxjLWrhLy5LLRpj4mXXgLufrdLGgBM96rXTBT9efZeLJHs+wRm1J1q8rKNNz+c06j0c1l0HsqU9b\ns93tPM8OfThIcvwS5riL+8oap2s8nxWc7xwimZB1X+iIsn7om303tfteFJkSQgghhJiBJlNCCCGE\nEDO4UplvSfcGHRRMeAkHxXqNVf8I7xXG7It0zNB9ApcBE0MidN2us6Q2MpQI+a6CNrdbRivBHVbi\nGmgg6eFoo8rU0OKABIP9CHkHdeUof0YnGqQ0htOxvetCPAQNwvVMpDbAATK2OB+47U6qLK/UkMuG\nKst2R5QFmYSzym6sVObj9Kizdv1a/qynQCIakfCT8o2ZmePhMkFqMWK7zfWpTpi0EzHtawgxH0HK\nXiI547KEfDDkY1LOckh+jFuzDuIhoQxHxxATrI50veCaY13DfB879F8mzixCYsvpxIM9nH0tpO/z\nmzcvtldnN3CeO/W/6ESC+6qixRDJEFlTsmeyVYwLI8YC1g2l/F+zxielK4w7FdpODzn3UHCcYt3E\nAtdCCbaHpNq1WcruKfkl1L7jeIoxd035tqLUiPYU3FjTksquWhbcn5CnmFCWEhYlQxYMpGO7pYOR\n8jKdxpRLcT50SzIZbdtFOetQMNlmAfckJVnW3Surabc0ZbSQaJZaG7eZWJtJo40SHE4UrvGR7vMd\nd2aP7zW2VSa5LfCcK/RTOv8TZTg6BPl5sCHSpRzy5vLeMWnrXX5xKjIlhBBCCDEDTaaEEEIIIWZw\npTIfo2Z0t7BQTgE5xA2hXxqx0rQNj+FhSmGO8GGIaOK9HUOGSJjIsy7LKCWE2nMMg7J+GKUBOjEo\nB0CSrODuGuDyY70qJlzrgisnn1tdTUsSh6Jp4AYZEXqmmwu31HtIKnWW6hb19YvtEk6900THDBwp\nJWW+LBGWxw/k7UWW/1Z8xnAhBSemmQ0tarlB/k1wgtYIYx/j+R2j3S0g65Zw/x3jGo5qOL7aLFWN\nXT6n7jx/VnTh5Gs+JJQP2NZ6tJ0gN1DaxX2t4DyqKQFBnmuZdLablhLWp1n+vPHIoxfb548+crHN\n5zSm2MabYyRDRT9d0J03TDvIHDUiKQUu9sh8wwhnWEVZLR+mhLRXMYluOnzfPFsh+SnGigb12Jhg\ns8eguMb2OR1SaOMDzp9Jg3u2CVqXMRYlyHysSeopt2sfoouKyZtbSm9BnWINPoxHQZLEWICkoi0c\nyDUSWxa46BF9mY6/HjfSLymhbnBn4n4PRnmZ31PYHzrfgPu6xrMd4YpruKwF/atf5XGw6/LrlAi5\n3CPWyov3pSy4rIdJYvOmY4nE6FzuwmTGe2qWMsMoxml+/xbBsYzEq1i+0nd31zcVmRJCCCGEmIEm\nU0IIIYQQM7hSmY+hP9Y/8xAPz5s0/7Ee1NDnkCszYQZ3XcMwPLbTdJiYjhzWzetauLCWSBhnO/Xc\n4NBiHUGjmsm5K1022KkMKUPhjsA1VwiblnQwhpArZIuCxzwMlA+6Ne4XQvLdORMeXrvYXlh2Ti1q\nyHNl3qeCdFIu4dpBAcahQkj+KMuFDSS/AQ2KDp7dBKxpCbdSn2XCAs+yQch4aZSOIOHA/Vdie8Ea\nWWMOk3d4bw+HZ4LE297MySkvLWlnopxn2J5OMMnklyMkWao7dE9R9mkhqQb54BROvdN8zedoXyv0\nx3ZFF2x0DK1xTiv8qWGS36MsLV1jwUTeALjwCshk7KYcvxITOuJ8hn21CYvDuzP7geMd3axIJsyl\nD1gfQanOIClzWYLDWjygXfe4KT1rHWIgb8NdgTwMyY9uNDOzhCSPTOxKN2AZknOizeI6g9sQMhcd\nnlAIreRyEiSWZh+kzFdXhx9nzcxGfj/g2qpQ4xJ9c6STDuc0MuFt7ncD+hfrl9Itx2S57XnupyPe\nW1F2LOmCjddD1W+xhLyLxLktllc4ZPr6iMtL8rnyXozF9FjG02CfbbDkI9T+27Xv3wZFpoQQQggh\nZqDJlBBCCCHEDK7YzcfYOOr4YJV9jTB5hRB4h1DsCkm/aBFk0rQEJTAhjEd5iq4MhiW7LocY6aQy\nyEqbA+e5aI0wNQsTFXAZMGxM+SSF2mvQBRFaZxK0Neok0UGSINW0VEIvof5Xi/vSdXDJ0Igz5tB7\nAbdOlfLrR4Ywb4JsV+Z9GtTg8iZLhGu6bQo4+yAFNsdZOqTds13hBpnZgGduoXYepEGEnsdVlqEq\nuDcXkEC6syznrfHeAW7RAdLjiHj4MFBeoxxyOb9/KOHx80LNPuyTECanxOasTYd4fgX35xoSw9k5\nE3Lme9qhjcMgamv8/mPCyJ5JAs1soDS0hgSwyNezwjOv8CF1g8/gtWGfZpGvbYnxJdkeuSW4kOh4\nvbv6X3dCF8zOlGbpbIJDFvuw7hzy7FqPsSvUawxuZUhhFa4X43sPx+YYnNiQXZo4zvZog/2azlbs\nh+fEa26ZCJImSny3JLQjLlMoK0q/kPaQjJhJbZNfztdpGdxp+OhQ+xES65pJh1lDleMOEmeiDdKh\nzuK1if2LCWjZxiF5tkg+XdVRtnU865AImMlQcd4wwob6ipxDlM30uEj5j3IzEwQv6Ew3SoRy8wkh\nhBBCXBmaTAkhhBBCzOBKZb6z05ygsHS6ZCAlQMLr+ywBMLpXwanWoubXiLlhfw65rIfTA6E7SgnD\nCg4YOLh+e9L5AAAgAElEQVQGhDFvnMe5J9Q8Oz7KySQbhMFLOD86SH4FnSV0VpzTtQeHy7TyYg1C\nwEvIWCwTNY5RAjkEdAMNSJ7WdZRp8z0pIO2Na8iRSODWGB1ASCIZ7gPkAESkBzz7CmH+Btuh7tJJ\nlgvNzNoVXZ5IxAd5uUN7HOGMGdCuWVvROiT6Q7se6f7Dg+2gq3iftxdVljAXi8tx8zEZYHChjdPu\nqeBgY+JYSj1o+3SUJjzDFSSD0zVkCCRS7Fj/DM85Nfm+FJCtzMwKuHnrJWptwvXldBzhooNcA7mZ\nkl8D2ScknwzSHtsexo59ssqB6PHMglOajmi264HSJCR7OsFYE471UJnsdQmZntIh+golPLqpfY8b\na/MZcLMtKB3n8YW1S0d+J+BZ0qjorI+Itsaxe8QzpqvbKIPT8bViPc3D4bjHY7CHYxyhg62iJAk5\nLyRDhbsUN6+u+VlM+AmJPyTvxXIESvx4vd5xrB6hDYx76gI2aA/lHnceRyqet+3Zv8Z3JRPYxuOj\nnStppxBCCCHE1aHJlBBCCCHEDK5U5mtR66cqmXAr7+OJbg/U5kPImUKHj9NywIDwbkVHEkKDw9kH\nLrZXCHuvO7oF6VTaSfTIBJXXsmxUlwhrIoq5RE06ylU9nGUjkwTi+EdwDDHBXYK0R9mC4eeuPXz4\nebHILrmV5/MfBiRLPM/Pb1lm+atEssShwLmhZt3RMQs1IXkppLOmZBJVhKqZ7HSVa7xRQt6tF9Xs\nuUesD5nW+Vjj6nzy9Q42yoJJ/xIS41HyQ2LPHtt0mpVBdbqc2nzB5QpXTYk6fcdIaNdT2qI7DSpE\nB/kkyGisd0mnJo65Qi00lu9qjnMfYi1D35GylyiYWLEeHGpvFfhsnlOBPkVpmK6kMiSZhKwPZ1hI\nzgn3q4+UMKI8eQjokKqCkxkOvqBOQc6hhLfHnbZgnVA4pAbWHqVE6Hl/ylE1Jb+RyzJ2HI7sABjL\nK7rt0MBWZxiP0HgqSK28MiaQrujOQ5Oi45FjenC49odfTmFm5pTzIFUxeSpdawVOkPUFKceH/sia\npVwqw2fi02PCyJp4cCmH5Rg7DuQw9u45pxLLSOiUpzOUz6oMtSDRl/HZ5Z72yW2Ox12LJRt3gCJT\nQgghhBAz0GRKCCGEEGIGmkwJIYQQQszgajOgs9gnC44Crj9gcU2z6fVTCdleaYntsD5gzVQHOIdz\nrKfpkOG1pzXeuR4k2pipF3dYZ9UgM28NXX9cTtv9mXV3xPYCc92B60xYZBiLVHqsXWlh5T1fH35d\nBm3JqcznvF5PZ9Ydx5zdelwhtcUCujRvL58x7fCw2ZYn17EP1n10+bPWWMPS4nnVxU5WXqxVo1XW\nWHAYa+yGm3m7W+fPMxbJxhrBNbbNWBQb6QBwSuddLiZ6fJL3OXlaLuJ8SMY9WfJZEJopAAqud0G7\nOz3L94vPjQVq1yh0XIUio7mvLE5ge+f5MFXDnqKsZmY1ipI3C6zZOc5rGwsU8u1wrKORa1HyNdPS\n3WD9FLMps18XeKBccsOU7kVx+FQXTHXAZS/MDH4GG/8Zi9UusQ4Fz6bAWFxj3d4Ca0VXGIu4LrBp\nuL4MYyBeDxm2d9YeLRb5M9hMW6xzHDGuV1izGta5ssg910k1TG3B4+N7Ayt1uT6H69B43w8Ks8+j\nPXLtLCsjMNN9Edau4XuDfafmemRmJMfauJHf3SgezZQJTEmBtpB2irPz/YlpCdiPFmhjSLkxYM1Y\njbbEKicV02cc5WM2KJLMlC8F1nd1PddPqdCxEEIIIcSVocmUEEIIIcQMrlTmG1FcsaBdmcUomeo7\n5GJmiJbpbvOmw9Y4QmJaQc47h91xQAi0RWi5Rcg5hTS9MTUCJQCGwXuEOxNknzRkOYjFe8P1M1yJ\nbWZQrmAtDYUZGYqmlOB3F668E5yh9BrZxBFuXp1maatF0d8yQcJq8j3pERqub2QZrYRs2hxlaa+A\nlOBLFExG2PYc94EZnXdlPmZsZlHaAm1qOM/nNJ5PZ0OnrnJ2mq/zfe9/f96F6Tmw/4DM/laimChk\nlVTsFNs+EB3kWW5bDYnGKB9ROkb7ZZrpPdnAaSdnWL1G2oLFEvcIckvJLOzcruNQVjfMeo4i2BWy\n8sNaXVB+4jbaOftdA0liiaUJNcoiOIpVs0pASH9yd0mW74iBGeORYmJfaoQC19jgXo3IWk8ZqUaK\nlxpSaY+lGFxy0NTM4I9x33h8pDmo43i1brEEg/fR2XewDAKy3YjiuyykyxvP9DIj+yPaL6tRMFcH\nl40UlxSbqPaN/VQwQ7Fxw/aeLPyQqblEJTRH/IMpTEp8n/S4vwO+99o+t7t2Z5VJhftXMIM+2h7H\nggrbLPqcmK0dfXZE9YwSEn/NMQLzA6ZG4D0K9+sOUGRKCCGEEGIGmkwJIYQQQszgSmW+IJ8wxI4p\nHWW+GuFXC7ISs9TmEOXpI49cbPeQ80qEAxdlDhlS9hlQfNfWWNHfM4wbYRZkOnpCUliEx5kRuYEM\nsWR4E9e5gMy3QMixgURFBwUNMUVJme/wmXnLJkt7PcLt9FStEHpe07UBGcIRtq8gxxZw6pQslHmW\nZcH0CBxbyKpOF9Ia6h1UF6t23Gt0q1DSaCBFOM5vjQzoa2QrXyMD+o0P5ALI77+Ztx3n16NPMDHw\n8QnkELSP5XHOPH9I9mUoZ+HPikVgqcTgH5ThWCGAoupykWUiFo1tMRxBXbUOEnyQbcb9rriCbYbF\nbtkGMNYcneR7fIy2tKinpb0g/+GzK1ZMoAwTauPyZh/eAdbRRRvOAc8DYxfdjpRH1wMrQXApBrLW\nG8crjulwUOJ1ZtEPrmwuh/A40g42vdSCBXSdrjXeUjiNh5DFHJneE5dK4BmzCWH0b1GQm+9Ndgma\nrZlRbeL2uOeaKe0xM3rJbPBwuxZ0hNP5zT6FzZ4rIuhWx9KEVGEJzU4TLygBl3wOeZ8BfX5g0feG\nkh8LqfM5cBkQrg1fg76nTXkYy+yuUGRKCCGEEGIGmkwJIYQQQszgagsdQ3pbMHTH4pKUgxDudUgM\ni2M4t4YcZjxC8rmehS8hwzArGwtI0p0WkpKtIRfuFMddLpEAEJIkXQ0VQuJlSWcBHGpMUEZnEB0U\nNu3WqBf5c1uKbLzOS3DzNcss1fQjCkbjXjN5HOUGJoK8CVmMyVL5hoah3QWdbZBX2nwfetyhFlKT\nw3FZ7iRgrXCuiyUkHGinBRJDsgjmjdMs4bG93ICD8QaKWZdwpwxIyEeJe3H9qRfbzcnJxfbRySUl\n7WRCQ2xT5hsgsTHJJ9vyWLCdIjEenvkxEmcuqvzeU8vuxwJ2s7M230dKWAXC88WONESnHwutnqBQ\n8tED+b5efyi7RGskCazgElrWlIBYQHY66S6LxnLk6OGqCwV+DwTdxCVkNUp71DA8WAqZFDH3tYoO\nqYISJ92eGUpw7L+UTWtIPAMcjn0Xi46P2M/hnB1QQNmx1KAPfT6fx4BkuU75C22c4ywdbyPaY4/x\nlMs7PB0+AatZLOLNpJqUoYLrnEk7g7mWSxngfjzO93GFguz8gA6vB1l0gWUsuO+U0JnI2cysxbny\n+wtTglhkmUXsOT/gQalIhmTfHOdZzJxFj/G5dIumu/veVGRKCCGEEGIGmkwJIYQQQszgat18CMU6\nwoBMssbkeXTCJcQrozkgH2cJF06HVfl0g7A+IGssNXXeh+66DgnjWFfKLMqQQfY4YrJN1olC8jWE\nvnnNFq45v8wQ/QL3osI5DJSk4OZL6fBuvsWSiftwjXx+Nd06+RzOEcZnQsZVB8kPmd7qGq69JRMw\n4j6jrtsZ6k6t4AqsENqtd2ShkqHkc9xftBdnUrp1PtdTyHwtPrtD/JjO0TVkqx7Hr4/gjIGsUtNd\nBsnvkAyQMTpcJ3Jnhr5A6yF7RcF+gHtMR6Lh9ZWhLTSQ1FFHq2hzW4PR1mqcQ4U2YhYdnZQVrz2Y\n5bwKcu6CDk604QYyxJKJQCHzDXCiUQ4a0e/oPEyQElhf7lAkLpvA9kg9g3XkmMy2mV5mUNMRzeUH\nwc2WcSYiZpLGEfe2mZa7fYw2KspqIdkmvkMSvlvWTBZLCQ8JQ7mMoMKJF+iPCe9lwlMmc2Q9SdbN\nOySO9sX7x6SilC35IOiS5LIWypNMbBlqObb8DmGCXLxe4Pj4LCrKw64Ej/vHmnoJfbCkpI7vmgT5\nfoUxmLJySekV7lrWQeUYxISnPeRmLku6ExSZEkIIIYSYgSZTQgghhBAzuFqZj3WMEMmNMk4O/TrC\n+C0SyLUtk9LBtQOn1zLEnBkORs0vZtILSfUg1SBsX+3U/2KyQiYobOBQYjh1CPWqkLQTMk4R5BOE\nounyY+Y2SAbRoUAnwuEdQ8ujHHpdIAEc6x2erpHkktJbR1cc6kLhlIMDBHrnAjLfEe7bcsznMyA8\nf7rKDrEBn3UCJ6ZZdG0VoXYaJJlVfv8HUGvv/DxfZ7jTeGZsyw4nDUPeZQN5cQlZF5IXa1YdEibJ\n6/F8evS15hiJHhHHT+gHlPaOKL1BJmJyw4QkgcWSMj0kjBXGB0pG7L5l7JsV5JcjtM8llhSwDTfY\n34OMDocllyZAS1kxGyCdaFxqQKdxcK4dvm92zKqIpJX85VxiGUDNJQQ12xqXKEDawbXQKE1ppoQ8\nyiSNzqSrDe4tPjdIkGY21jxXXI9nmaeDi3bAQBIS0NIsjHE9OOH2yJYDZMFh4DjL1w+fgHVzHrxm\nPAdssy9weYxReoScxVqDBe7Rkec+uCr5PQsXJQ1/SNpajPgegET4QcmuOS4wiSvq7tGxv7yex+rg\nEKZUi/GlDNfP5wnJLzhwWTcztyMmBL8TFJkSQgghhJiBJlNCCCGEEDO4UpmPjq4e4bQWCQ0ZlqMj\nJNRnwhywCHWx8h6e8vHrajpxHV1LQW7BPkz6WO/IfCGBGOsVIdybEIp0hFMpKywWTOwJJwI+q6QT\nA1NgOjRKyhOQJAo7fPi5Ocqh1+VJ3qaT0W/AzXaeHWx0YVBSTZAnmPyzxetVn9+7HHIo+DpD+2gT\nN89zQlG2v7Lh3TUrWyYQZJLIfB4ryBtncPANSOZJ1ylde3SC0gFE92Y5wNkCixxliz7F8z4UrGU5\nUIZF3zyCLMa2H8ocOrPn5U0m1aT00leUsvnbDrI56+lBpgsu0h3HUIE+XOO4dHSyLhjryoWRhnIA\n7pFD6hkhMbHf0SVEiZhO1XQJz5O17egmrmo+A9aXy69jSLQaY1cwi0Gq4/jrQXblsgdKShi7ce01\n2o3XcH6aWUnXNJ6H87xXqAsHeYayEGuCJjhT2XaCY5vSmVMiw30MzkxWJj0cCZI3a4IW/M7i0o9Y\nqC+/yoS6Nb8fpttgiQ68wP52Dsm6wPdjwncXnj8Tx5pFR96+5QwNXm+CO55HYuJcNFycKiW/EbI7\n5XV+B3EOsazDh90WRaaEEEIIIWagyZQQQgghxAyuVObrkJSxXefQ3XqdQ5ec3tEc4QgV0zViSPZG\n+aBkrJ7HQViWifQYo65DDT3WLIvOGyYNpMQWnSLT57Fg4jcmFR2nE2zSMcUEiwky1ABZyXrYbMbD\nh5+Pr+UacUskRTyG86J69JH8hlNYafBwHGF7Jh1NBRx1iL22SPK4PsW1w0dHied8fZo/iyHvVQxt\nJ4ToExxZCcdt4dpqmYAWUWzWWqshSdFdFqRsXBuvc1/SOtaoPCRjT5kEdc7OUWtxiWSjQdOB3AIX\nD+WsBtdDyY/9oMJzG9EHBySJTJAV6HAtqpi0k040SoML9lm6eCDhMuFnSVPsOO0GYuLZUAmMCQOp\nn3Fg6w8vwVM6ZK0xJkrmM6MFtV+zjdNth/p4+CwmB2aSUubdTHz2lH7pzISk1JTxN/4I92MHuTSh\nfTGZZQG5qcK47Py2K5moEuMpHX/j9NISuv8GSkf94ZMj755UqOVY2uTrvMchXMJnzueAezTgu4Lf\naZRh+cy7EksnICmno7z/rmOVZVGPrtE9ij6MpQ31Akt5MEb2TJAb8rpCRkSbZ1ejo5bJPAeO/XdZ\nN1ORKSGEEEKIGWgyJYQQQggxgyt28yEh1rjE65ShkLQTr7KmXgg5QhpgUG5EaHnEin6GYuncYK28\nirWKEOp1j7eLbh1KI6z5l4KxYroeFmXBEEJnJraRoWWEKOEw6uCSW69Wk68figZJ9o5Prl1sHx1n\nSapgiJWuveAqYawakgGaRMitin16hGcfvZnddQzOt5CW+bxXOwnZmFTRcH+ZDI4JSdlz6BYNCR/R\nplJIBogkhJCgTq5lifTkJN/Ha9dyPb7FFSTtHOh0QZLE1WlOThoSQFZMuAjpZpiWPejSLUf2A/Qh\n9ATWgqPTsIHzlQl7zcyKmi4zyv94DpTLHdcPHYLyEVUcuooK/GEFZ1+QTyAr2J46fYdiRF+jUy/K\nVtPJHys+D7YDtP0SF9/h/OnGrJC0k9onE2fSFUj5dti5JwP2o8NsyXa3gCQFCY9yDsdoSrCU6lp8\nNp3YXELCWoxrjBtDOrxka2Y2Yjwq3af3gYbFvskxmO6/HkmwB76X7kxu4yEujlnTFkswsHSiY3tv\n4/Os8P1dHzGhNmvn5c0Rr7OOIB34Q09deY/zHUszBsxFuo79BZL9niU3+1BkSgghhBBiBppMCSGE\nEELM4J7V5rOe9b8gT51DwmNSPmMYGInfEMasEfbvEYpOkOeYFJN181jzrIAc1MGpsxt+pnQzchth\nfw/7IISM4wyh9hIkCdYUTJQUc4h2RL25MyTGPMc2698dih6SAeUzhzTJuzUEWQH74Lo6OqTwXNsg\nN+CeQGpZQ16hnEEH5hLtoAu+K7OO4V24kpZ0tMCRd8ykpQ2TR+Zjhhp0oRZlPo9jyKIf9vSn5e0P\nf/rF9rUHs3NygcSZh4RtljLnwLbW5Rs+MkEhk9TioTSoC8aEqYn9g1Ib2um4nq7ZWBX5Xi8gry52\nknZSDow11iBjQSZo2Frx+mhs24bX83E6jF9MRsx2GOQg1ua7hL5JiYSJgmNiU8o/+dUKjizu3UMK\n4jG5FKEscv+oqiy7lpB1qJz0xjaHM9ups7hYZpk7pHWlQzLByZzQdiA7t6ylim2eH12no1H+wRKE\nkVLQtOPvkDAPrvu0s4+JWrn8xHgv+R2C9zJp5RJLE+LlQObDeDdgyUZwRbLXFVGa5HcEPy759HiZ\nUBcwLBFgYuOB8wO0q4HLQjgm4NnyeeK941264BWZEkIIIYSYgSZTQgghhBAzuNqknZAGzlFjaES8\nbon4XlnnsHEB15MHR0PwbmF7usYfpTMmdCtY444OvJDQLEpDIZ8fpYFQmw+uEcgbPZ0luAYmGGRo\nmbLFiMRiA9x8a9a84/7D4ZN2drgXDRIkHh/n8P4xHGkPQqpa9wwx52NSCinOcvtI55BRKAXRYRMS\npU67kHqGquuY/JKJ/mpIOyfXslPxGpKTNgh1c3uxzNdfhUSzcI5Cwjw6yvs/9OCDF9vXH0JSVEiK\nxSUl7SzhbkoDZRLI7nDgDqhtNkJ6YBdxyKJ0zo1MlsmIPKQ9yo49xg1K+UzAm1CL08ysYsJMm+5H\nNWqBsW4dZS/W3GQbo/zJRH88Pp3DlEA4Do6XkOgxnCdG+AKuuBptNoyDzm0cFGNRVUzL+tSjmMCR\nYyjlH5rf6CBd7CRgLSEXcwxeYyxYwTHWrvfIh0b3F6Qjykv4XA9KFa+NfRluz7tM8ninUG4M30F7\nMkKnhDECfdODBRVvZV8ZWdcQCU+DsRyfxdqHcMvVC3zPpv3TjLKCgxfLRThuFwWdxkgczO+4cE6Q\n19HXVnS4o8+2aEeUs/teMp8QQgghxJWhyZQQQgghxAyuuDYfQqtI8OUI7zFpWImV9eWI0G9iyBxh\naSZMRJi5hGWAjhYvGGfm6v49STR3krJRwuOslG6CUK8J8laiHIDwcMeSerxOuNWirIBQN5Iq9pBR\n7RLCz3ThVZAMHnrw+sX2R8CRRufkCiF9x3PqIB3dvHnzYvvRD+TtU7gU15Balkf5OJSF+MhYS/Fo\nxxU3jrmNLCDPnZyg7iDeQwlviddPTrLzKNSHQxsvIY0cL/PnPgXS3lMgi1IKLPYk7ZsL61Q6JCmn\nrID2O9q0TDJA4u5wHCbhjAkscQ5oy45+U+CYNeT0kk4d1ve06PShBDIGNyhcZnRx0fFnlBIgt6Dt\nMQEiJXvKkKwvZ5DdixSXDhwCtvlw+FAwj7Ir34B2SkkZ117VTJaKxLTB5YcxnaNjqL1K51Q+h+Wu\nMxOy5RlqRZ6fs9Yr5VXKyHCRhiSybLNcIhDsuJPvrehgRHvs9iSpnQuXabR0UZfT3310mrLNlmyb\neBA0/EFRjW2Zai5kQdau9TQtee7mMg3niv28QC1PuvHDsbBsA5IkvzvofG/R75hQl/tzn5Bc+S77\npiJTQgghhBAz0GRKCCGEEGIGVyrzsaZRH6LeSAJWsY7cdPJFhj2Z4I0JOXvUFKsRraMbig4buwP5\nZNd50zFEibd3wcWT9wkJ5zpKb5QhUAttxbp7SAbYTycZ6yE90GVRFoefM9NVQrfOEWSxD/uID7vY\nbo6z/NVRnoH0wDpaN25kae/keq67t4JjcUVn38j7BicgzrmBu6zcccXxOS2xHx18S0gaC+zTQEZu\nUDtqCQnv6IjvzZ99AgnvOmrwPQC5kMe5HJHPLDHp3Z46fedjvq+UOX1PwsCugAyLWo4DZBgq7cGd\nhzC8B6U8P/8U1KOoJTARLvvCgF7Y4/PWkAlZ84uS1j6ZL9HNiPPoWDeT7jGc53gJ0hCddAV1G9YM\nNUpEhtcJpSDUU8OzZI3OkHSRQyvdgrh6jp+UrynrmUXH7/kZ3cuQWoNUk/fvg5t6ug5keCKsZRgS\ndUI6gnOwx8n1/eElW7O4LIAqJGW+ms73MN5POxV5v5n4ms85yHMYX1kbls+GX3Csa7dbsbBE4l1e\nwxDewwPTaYz7PUz3Lz5zSr4d5g3c5j3lF/ndjrWKTAkhhBBCzECTKSGEEEKIGVypzMc6TmFVPlw8\nPeQDukOsZzJPJoRD6I4J55D4jav1Ke8Ue8J7IUwa6hnFgGU/TofoQ1JC1vNjEk6E95koj69HaY/1\n0rrJ/Z1hc1xccQniEB0WvHf1Aok6n5Kva3GcXX5dCI0jDAtJ6dq1LK895ak5mSWlmS7cByTtw+tt\nNx3OL24hfR5BqjvaI+0xOSeTCjKJ4RLHOUENPr6+gIxE+a/CZ43BVrQbND8MdLdYouslv1yW+XW6\nZZm40G3aDdV6luco7dFF26+ZSA+h+m468S0TjVZlfJ50HDGMT+mmxD2mBMbEuVVIJMjkiawXxvqb\n032cEkaoUfpBIsh8Qv1BHL8NbkwmW4QjCy5jjkuUuEdI811HORXngD4+VnA9083Hmmj4rL7PrmQz\nsx7LAlZw8LGmHCW2FGrw5eM4a0WiTQx7kiyzq3W4d0wEyeu/LJmPSTWDUzPqUxdblCTZNnkvKIPT\nnchmGl2edALi/qL/ejiHaQeeWXT6UYbmV2Xop+X0cZl4k+M/nwPd9NyHiT35XUBn8niXY60iU0II\nIYQQM9BkSgghhBBiBlcq8zHkGMKP2CfUs9pTXy+FZGJwErGWUsXaXqznhvPhcRDqK1mci+ew4/gL\nyf1CIlEk8aNbiXIDw6MMfe+p7UXZzhGLZSI2hu5DqPsSEj2GZKQ4/JLyF+TYqqb0Nn2NlCeOjxeT\n+0QpYbpm1bAnaRulB8o3ZtExU8EVyrp7+9oIt/mc6HhbwG1TM0ktQtisR9WyH4Q6VfG8D4WP+dra\nFR2iTNAHZxsS7A377gsadtftkaxZX+2MiTchyYyUKig3UFKLdbTqPXURGbp3fHYFV1pZoAYha8F1\ndA8huy5dheH5sPNTVuByh8PLfJS/Sxbn4/0KNet4znRHo8YZ5PLkuG+QVIoKLsjEpIs4H451w3Tf\nL3b6ZiyJOj1ms7Yiax8m1p2j9Mg2Fdx/kEKZ05muwD3jfroEydbMbOzZjpAYs5tu/7wvTEwd6t3h\nWdUjv1vxnJkgNMiF6PtcQhNMhJDLdhyrbPNjYj1dOimnJdN9Tthxz3IcyrDUdvtuevkNv+O7Nc/t\n9igyJYQQQggxA02mhBBCCCFm4JcRZhZCCCGEuF9QZEoIIYQQYgaaTAkhhBBCzECTKSGEEEKIGWgy\nJYQQQggxA02mhBBCCCFmoMmUEEIIIcQMNJkSQgghhJiBJlNCCCGEEDPQZEoIIYQQYgaaTAkhhBBC\nzECTKSGEEEKIGWgyJYQQQggxA02mhBBCCCFmoMmUEEIIIcQMNJkSQgghhJiBJlNCCCGEEDPQZEoI\nIYQQYgaaTAkhhBBCzECTKSGEEEKIGWgyJYQQQggxA02mhBBCCCFmoMmUEEIIIcQMNJkSQgghhJiB\nJlNCCCGEEDPQZEoIIYQQYgaaTAkhhBBCzECTKSGEEEKIGWgyJYQQQggxA02mhBBCCCFmoMmUEEII\nIcQMNJkSQgghhJiBJlNCCCGEEDPQZEoIIYQQYgaaTAkhhBBCzECTKSGEEEKIGWgyJYQQQggxA02m\nhBBCCCFmoMmUEEIIIcQMNJkSQgghhJiBJlNCCCGEEDPQZEoIIYQQYgaaTAkhhBBCzECTKSGEEEKI\nGWgyJYQQQggxA02mhBBCCCFmoMmUEEIIIcQMNJkSQgghhJiBJlNCCCGEEDPQZEoIIYQQYgaaTAkh\nhBBCzECTKSGEEEKIGWgyJYQQQggxA02mhBBCCCFmoMmUEEIIIcQMNJkSQgghhJiBJlNCCCGEEDPQ\nZEoIIYQQYgaaTAkhhBBCzECTKSGEEEKIGWgyJYQQQggxA02mhBBCCCFmoMmUEEIIIcQMNJkSQggh\nhJiBJlNCCCGEEDPQZEoIIYQQYgaaTAkhhBBCzECTKSGEEEKIGWgyJYQQQggxA02mhBBCCCFmoMmU\nEEIIIcQMNJkSQgghhJiBJlNCCCGEEDPQZEoIIYQQYgaaTAkhhBBCzECTKSGEEEKIGWgyJYQQQggx\nA7FFh48AACAASURBVE2mhBBCCCFmoMmUEEIIIcQMNJkSQgghhJiBJlNCCCGEEDPQZEoIIYQQYgaa\nTAkhhBBCzECTKSGEEEKIGWgyJYQQQggxA02mhBBCCCFmoMmUEEIIIcQMNJkSQgghhJiBJlNCCCGE\nEDPQZEoIIYQQYgaaTAkhhBBCzECTKSGEEEKIGWgyJYQQQggxA02mhBBCCCFmoMmUEEIIIcQMNJkS\nQgghhJiBJlNCCCGEEDPQZEoIIYQQYgaaTAkhhBBCzECTKSGEEEKIGWgyJYQQQggxA02mhBBCCCFm\noMmUEEIIIcQMNJkSQgghhJiBJlNCCCGEEDPQZEoIIYQQYgaaTAkhhBBCzECTKSGEEEKIGWgyJYQQ\nQggxA02mhBBCCCFmoMmUEEIIIcQMNJkSQgghhJiBJlNCCCGEEDPQZEoIIYQQYgaaTAkhhBBCzECT\nKSGEEEKIGWgyJYQQQggxA02mhBBCCCFmoMmUEEIIIcQMNJkSQgghhJiBJlNCCCGEEDPQZEoIIYQQ\nYgaaTAkhhBBCzECTKSGEEEKIGWgyJYQQQggxA02mJnD3H3D3b7nX5yHuHnf/OHf/FXe/4e5ff6/P\nR9wZ7v6wu3/uvT4PcXW4+6vc/Ydu8fdfc/fPvMJTEvcId0/u/jH3+jzmUN3rExDiwHyjmf1cSum5\n9/pEhBCPn5TSJ9zrcxAZd3/YzF6aUnrjvT6XJyKKTIkPNZ5jZr829Qd3L6/4XMQV4u76cSjEPUB9\nT5MpMzNz909x91/aSkM/ZmZL/O2r3f0t7v4+d/9Jd38G/vZ57v5md3/U3f9Xd/+/3P2l9+QihLn7\nz5rZZ5nZa939pru/zt2/291/2t1Pzeyz3P1Bd/977v477v52d3+luxfb95fu/hp3f6+7v83dv24b\nfr7vB4or4rnu/qvb/vRj7r40u20fTO7+te7+b83s3/qG73D3f+fuH3D3/9fdP3G778Ld/6q7v8Pd\nf9vd/5a7H92ja72vcPeXu/u7t2Psm939c7Z/arb98cZW1vuP8J4L6XcrCb5+2y5ubMfr//CeXMx9\niLv/oJk928x+aju2fuO27/2X7v4OM/tZd/9Md3/Xzvv4DEt3/wvu/tbtM/xFd3/WxGf9IXd/55NN\n4r3vJ1Pu3pjZT5jZD5rZU83s75vZF2//9tlm9moz+xIz+0gze7uZ/ej2b083s9eb2SvM7Glm9mYz\n+4+v+PQFSCl9tpn9vJl9XUrpmpm1ZvanzOxbzey6mb3JzP6mmT1oZr/PzJ5vZl9hZl+5PcRXm9kL\nzOy5ZvapZvaiqzx/YV9iZn/UzP49M/tkM3vJrfogeJGZfZqZfbyZfZ6Z/REz+1jbPOcvMbPf3e73\nV7avP9fMPsbMnmlm33x5lyPMNusYzezrzOx5KaXrZvb5Zvbw9s9/3DbP8yEz+0kze+0tDvVFthmf\nn2pmrzOzn3D3+pJOW4CU0peb2TvM7Au3Y+uPb//0fDP7/bZ5prfjz5vZl5rZC83sATP7KjM74w7u\n/kfN7EfM7ItTSv/nQU7+irjvJ1Nm9ulmVpvZX08pdSml15vZ/7P925eZ2fenlH4ppbS2zcTpM9z9\n99qmQfxaSukNKaXezL7TzH7rys9e3I5/mFL6Jyml0cw6M/svzOwVKaUbKaWHzew1Zvbl232/xMz+\nRkrpXSml99vmy1dcHd+ZUvrNlNL7zOynbDPpuVUffIxXp5Tel1I6t80zvm5m/4GZeUrp36SU3uPu\nbmb/lZn9d9t9b5jZt9mmPYjLZTCzhZl9vLvXKaWHU0pv3f7tTSmln04pDbb5QXuraNMvppRen1Lq\nzOyv2UZB+PRLPXNxO16VUjrd9r3b8VIze2VK6c1pw79KKf0u/v4nzOxvm9kLUkr/4lLO9hLRZMrs\nGWb27pRSwmtvx98e27aU0k3b/Mp95vZv78TfkpmFEKd4QvBObD/dNhPnt+O1t9vmeZrtPNOdbXH5\n8MfImZlds1v3wcdgP/xZ20Q3vsvM/p27/x13f8DMPszMjs3sF939EXd/xMz+8fZ1cYmklN5iZi8z\ns1fZ5pn8KKTa3We+vIWszuc82ma8fcaefcXVcDdj5LPM7K23+PvLzOzHU0r/et4p3Rs0mTJ7j5k9\nc/vL9TGevf3/b9pmQbOZmbn7iW0kvXdv3/dR+Jvz3+IJAyfJ77VN5OI5eO3ZtnmeZjvP1DadX9xb\nbtUHH4PP2FJK35lS+gO2kf0+1sy+wTbP/tzMPiGl9ND2vwe3koW4ZFJKr0sp/SHbPMtkZv/z4zjM\nRX/crnP8KNu0D3E1pNu8dmqbHyxmdmH44Y+Vd5rZR9/i+H/CzF7k7n9uzkneKzSZMvtnZtab2de7\ne+3uLzazP7j924+Y2Ve6+3PdfWEbWeCfb+Whf2Rmn+TuL9r+kvpaM/s9V3/64k7ZSgk/bmbf6u7X\n3f05ttHxH8t18+Nm9ufc/Znu/pCZvfwenarI3KoPfhDu/jx3/7TtWppTM1uZ2biNZHyPmX2Hu3/4\ndt9nuvudrPUQM/BN7rfP3j6/lW0mtePjONQfcPcXb8fbl5nZ2sx+4YCnKm7Nb9tmrek+/j/bRBa/\nYNv/XmkbefcxvtfM/rK7//tbo8gnu/vT8PffNLPPsc0Y/N8c+uQvm/t+MpVSas3sxWb2EjN7n5n9\nSTN7w/ZvbzSz/9HM/oFtohYfbds1Fiml99pmJv3ttpEdPt7M/qVtOrh44vJnbfMl+xu2WZD+OjP7\n/u3fvsfMfsbMftXMftnMfto2E+3h6k9TmN26D+7hAds8x/fbRh78XTP7X7Z/e7mZvcXMfsHdP2Bm\nbzSzj7ucMxdgYZv1h++1jaz34bZZ+3a3/EPbjM/vt806xxdv10+Jq+HVZvbKrUT+n+/+MaX0qJn9\nt7aZNL3bNuMsl778Ndv8YP0ZM/uAmX2fmR3tHOMdtplQfZM/yZzxHpcKicfLNuz8LjP7spTSz93r\n8xHzcfcXmNnfSik957Y7CyEuDXd/lZl9TErpT9/rcxFiivs+MjUHd/98d39oG77+C2bmprDzkxZ3\nP3L3F7p75e7PNLP/ycz+t3t9XkIIIZ7YaDI1j8+wjTvhvWb2hWb2oju0iIonJm5mf9E2MsIvm9m/\nMeUhEkIIcRsk8wkhhBBCzECRKSGEEEKIGWgyJYQQQggxgyst4Pqnnv+xF5ri0GV5sUDer6bK87uq\nLC+2S6TULIp82inlPxTYZ7loLrbrMm8PY05vwjydPOa27u3m+LdIh8Isn+OY3fOcofK8N2mONqy6\nPr8XSusw5NfXa7h+h7xT8rw94N6NkGyHfpjc50f++W/wtB83r/nm/xQnNLlpQ99jO59P33E7XyOf\nx2JxUWvaBtygYczH5P00vLcscrvpcD97bI9jlLfRLKzA+/k8+j7vVKJtVnnT2Cr4CWWZW0VToZwY\nc8XiuXqR9x9DE8z7/6W//qaDPEszs2/8jjdcfHhsj/keO68t8Ybl1x33jveY94LX1qNd8L6z73dt\nizfnza7D6zvLFcoa/Rnnt2hy2psR18DrJDWeFZ85x5oRD4htta7yOSwX+Th1g2PiON/05Z91kOf5\nzd/1C3iWPDc8szR9zmkyL2NkHKbvW8x7nPfhuOQ2fYl8RoXH3/gJY2saedzptuMl26Bhn3xcPku2\nR/ZHPmO2x3gc9OsmP+9X/JlPPVjf/N7/47cubuDqfIVTLbCdP24YeI+mv784dvIaUp/H43HI2wnH\nLHBjqmr6HAreX4+3IqG99fiO6DnwOL778Wz5fEI75Pcvnk9d5+9+Xmf4zkIjaRZ5fHB8k3/VC59x\n2+epyJQQQgghxAyuNDJV8Jet59lgxagT9q9K/gLIp1pViDrh1x9nmxVmp8smRzk4y+UMtvDpXypV\nnV/nr9TNjpwl5xm2IXrCc+r6/Ev65lk2/Q2MBGCWXFd5fwQtDME46/HLgz/OO0R8LiPjZLPIudYY\nveEPW/4m4nNteN/xhxG/chkRrBr8ShnzM+h6fBijIyFKNR0p4q+3zXtwIgVvdt6s8cuTP1NKNGD+\n8ma0skYIotgTdQrRLkRWep5rupzfP6vz0/wReFp8Jow0MloQfiHz1194Hf0U198iQsvjNHV+zj0i\nUB1+OfeIWO1GlgqMC/y1OSC62ONY+yNT+Th8Pvw1y1/XZcFIBSLiHcYsRKYYiT8U5+t28nW2eEag\nQsQqREoZVjfsj8jCwKjTvsgX1ACcAw/PyFKx863Ee80ICa+B6kaJ/suoWLUnsjp0fPaMTOXtukqT\nr5d4fncS1Xs8rM9vXGy3eLa+J2LDyE+IFVL1WOXvn5JfLvju6jvkn+Yx8Vm+b9xFuH43pOO4Tx3u\nPQNTVIqKcjqSHwP2GGvQB4ch368aYwofFSPf6zZfc4iI3QGKTAkhhBBCzECTKSGEEEKIGVypzNdA\nbhtKLGjDPiX+VSNMTtnDoXMtsE9DmYQyHySpquDCNoZxsUC0nl4sWuGzNu/HQviwWC9vr9Y5bHjz\n7OxiexzzZ68Q6kyQDJoFQ6VcdJ5Z4FwpVRQIB/eXkEusqrN0ksITRLgdr4aFyf30Yn0vpyU5ygGU\nXccRchT2H4Nkg8WYkKbGMZb0opHBceZrSEw1n3eQRrhIeVoWqtC+kjFMTsmT3ZELOyF370rNB6JI\nkPAYmEfYf+zy4tcBoXEuNOf1j5RM0I8KSpgwWVAi9AHHofxLSRn9rIir9IMcXKCvjR32Q3soKWO1\nkBJX6HcYL9jXuBA2yMowwfiQx76xRzuqDz8EU6pIexZ8R4kk6G15nyDl5l16Xjv2CdLeHum/2CPx\nBzFoR8qmrBjOiUsEEuXo6cXFPBEf0CbC+Ijnx3uR+H0FOYvNsb+cMoF9m/sdDTslxv4U7tH0EhpK\n82OHZSahT+F7A+1o5Oein1bh+2fa3PVB9wW3m0sYQpvE90XN728Yk1KQ9rh8J2+3GL8LfL/QUNBj\nqcGA5Q5NHb/vb4ciU0IIIYQQM9BkSgghhBBiBlcq8y2Prl1sMyxJ81RJRw9cXHVNSQ15qSArHC+z\n9HSEEPsSkhTdNjW2j45y+HC5zNv83KKMt4vuA4aTBzoCEBJmTp0OriKnxgD5hPuHfFcI3dbIm0Op\nYwhSzf5cWY+XArm7xpa5mHrudbEVcmNBUhoZhsY+PA5D+EeQWusarjA6syDhJXzWAFnIiyh9Ugzp\nEeoOjtIC9zdRbkC78GnJq0LIOLjlEuUGnAQtm8ElczldduyzlEDVg3lnSub1GplDDM8KkkSH8HmN\n/lWfnFxsN5BPuhb5x2BIY34w9rMC97rYyQd3VFHyn3Yksl8wHU9aUVbJJ1KW05IZm5Iz6ViBe1RA\n6hgxpgx3JyXcCew7dNLRbRZkd7yX+YHYHEfms6PsijYRc0BBaqpvn6uLUnYR9b8dlxzdopS2mOuO\n7RT7oD0W049yR5LEue5xqY5BXttzzJkMbZbkUk/3G9o1lzbwe4DSOY5ZwU3fou93cPkN6MspyGW5\n/barfNRz5MDa53bdpeWSD4yRXFJD1+0Sg1PJZTcctPjVR6MiHYkjF6HQ/Rhb/d2gyJQQQgghxAw0\nmRJCCCGEmMGVynxMtknHhSMkXMOtxYRoNaQ6r+Hmo8x3fHyx/QBlO0h1DO4tESa8BumBMh8dAJTd\nzMy6YToMuEb4tUeIe7lgKQs4utbTyQcpSZ5DemB5mDKUC5gujxOSsh0IyosDs44aZQJImbgnXUsJ\nD+0AIenCKM1Q+qRzCucDGSVhu8V7q5oyx/4SBwXkJoaMF5COK8icyXnNLIHEpHrYpOMPv2fYvoIT\njg6o8u4Syd0pQ3vzYpvyHCWDES63cY199khnA5x66RxSD55Js0TyVxy/pYxIB1eirMLyPvF58v6l\nelqK6uh4pasIz6FkG8aYxXOinFs4htQODRSJBxPcn306vAOMDqaB/YtSGpPLUsILWTUN+2S6IKlT\n8ptO7Bh1Y0qz+CiOY7vlRyjncbkApS0mkuS1Bf12OvEmP43tI5QCwxjXo216SBZql8Lq9NGLbZbl\niolU8+t0qiWONRhHfKCOjmUpvDa0zYJLHOAE7JjIF+MG79fQRZmP0nNHR26H75R1Pu9uTRdxPtfm\nGMsFjvJ3v6dp6XykM5kJPPf0BbvLoVaRKSGEEEKIGWgyJYQQQggxgyuV+axgjR0mU0Som/IUnEsV\nZCUmT1wipMnknEy4dbLMn+sIMbKC/APXr19sH8EVyMr07Y5alvYkk6sQQl5CGkoF5SA4NEJdQEgA\nDKFj3rtm0rwQQWfVbiQ5PVj98kyQM5yul3z+4bkGSWY6ISVLIQ04abq5giOPtbkQhq6ZSY8pTnn8\nFEPPwekElyAdYws0X1ZLZ9LOoqT8CUfLnkSibFJ0PcU8q3yul5O0s3JIeJa3OySd7eHWMdbUwj4p\nJKBFH0cboduyeeDBi+0lXZGUkugMQ7tmvylTbOQ17n0NN9/IhJaQ+Qo+H8oSdG0yqSwdbUy86Wz/\nOKEKSTshn7R7lgrMoYUs4kjyynppvF0xZeW0Q47SDJ8H5VFKinRBj+jLHeVRnAMlqH7nljhlPp4f\n9gl13bB/uDacX5A/eRy6H3u6/+Dgo6xNVeiSQhP9Oid7phvV8Z3QIqlmwjgyYlDl90YRxqDpZTZp\n5PHz99XZaV4SEJKI4px5bjvG6eDOsz1O3Z4JkvEdHF3t0w7Ovph2pNKROfb8zsVnMTn2Ol/znaDI\nlBBCCCHEDDSZEkIIIYSYwZXKfCVlvgphxuBWyvs0qMNT4XUm2yxZwwcSQMPwNuSAusn7LELSr+kk\nYyHJX4rx5xph89UKIeFQFxDhfcgNCziDetSiYgLPNUO3Bd1QqP2HEGhMUMbkhnZw6EhjaJSJ5EIO\nyj31rxpIuWWdz/msPcP+uA+Q7ehsKwq6iuAWQw3IepE/a7WKLio6lChhLlgXqqILEVcDGYMuP5Yt\no3uI9yvKfLin4XYx+efSLgPevwr3LHl+vaZMirZ5ts71rJjANaEOXkERgD/hmFwTsvuDIVku3Tl5\n/wYO391fhUOQACjdoO4e5DA6KavgOGMtvz2yV0+ZE2MZkg4PTBzq7OP7Exo+Xlompwx1IKcTxPJa\nQg1USlt0NfJmF9N6ISUVL6edfY5j0jUd6v1ZHIOZSJPLQNLOex4jyPGASzToNgvJl+lkDW9mwulp\nyf6QnJ/duNiuKWHhPLpVboM+oiZkzeSXrLU4/f0wBIsg5Gj0Fbrretbo5HIEjHeU+Dfnl+/3IkjP\nbEDovzTFBoclXKtrtE9eM2REthfW36UD20Ntyrt7oopMCSGEEELMQJMpIYQQQogZXKnMl/Yk3GOS\ntZLyHKQtynx0ZYSSPAgnMnEZdxphFRmKHCaEISnWhQsh5h29jO4jnge2e7pD8HoValTtC4Pn12uE\nLml7GxFz7+DWYHK38hJ0PtaaY72tdTvt2mNTGyhNBjfTtKQaSnUlOhlzGLpiQrqa4Xk+Pzg56xjC\npXTMu0X5y53yCR2JlIjheIM811Ceg0TaI0siJQY6TCipBkfsARkGOIYoe3SQD9gvOjjGRjxPSAAj\nknYy6W6DenRLSGQVYvhLyDPLisluUbsT+wy7CXUh+6zZ3lB7zHBtPVyIwd3FZLOQJygd8nWvkFDY\n4QqGrEyZb7cO3SFg0tXS6QRFrcw9tT5HLD8oKMGzTh3OOdFFi7FoAUc0ZcEaY1Fl0318jFZW62j2\nLqadw3WoswjJH2MivzcKyEsDxi+O/fukQDr7EuX7S0iObGbWrbKMHr5zgp2R18llMPjeRNs8P89t\nn+7Hju66jt+PkMch3w8dx9pQaBWfG9u4428D+k6NpNZsDwmSX4VrqOC6TjiOIWEoa+N2cOcxSSzr\nAbOxpp1lPbdDkSkhhBBCiBloMiWEEEIIMYOrTdrJelnjdMiVyb48pAFjKA6vInTNJIkr1LLrjGHJ\nHLpcNDkE+pTqKfnwA0OalJ5iGDcZkonheugMayEr0rezYp0z1gZiaJkJ8XjvcByG3yl0FDiOX4KU\nkJwyF+WDDK+FyRY7hMZDsjnUbGOttQWT0CEMfbzI+xwf5X1W53mfbmTIN9+hZrd8Ex2frKOWIKlC\nkmNiwQHn1MLNVpS5XhQVz5BIDq8zASLvVw2JkHLZIelWH7jYHlCbcH2a5b+ygwOVCS/p9GKtLT5P\nyjuQ9haox7UoKJHlz1rSkcbnRMl3x3lDaYG1Ms9x93u0sXPIfHQ9nSPJp0FKaCBjjXucmtyfywvK\nBm7WerqO2BzSnlp4oexecFBP16kLyXUxRhdw/NVMXIz3LpZwlFHWhHTS4PgNk3zuOPNaPMsS9V0p\nz7SU5waMRwPGVia83JPJOEEi6xNl92kXXUjGe5ey0J2yvpmTZA4Ym6qK9R4pSeK+hL4znXSW1xmS\naOK7j/In+/IRkl2PkNfYH5ms2sysZ+1IHLfidwrGxSWzJeP14KSkUxVjEJeg0JHanedxbQzLbPIm\na1zeCYpMCSGEEELMQJMpIYQQQogZXKnMV1X7Ehqylg5kq5CEEsdhckNE6DqE52/S3UMXDsKbazhX\nrM6yYI3kgYyYdy2Fuli7qULImon41pT5cLBThBl7XATDxryeFBw0CEWzFhpr1fGeXkL0ue8pIzL0\nDEcG5Vineyi/t2UNNsimJ8d7ajSOSKi5zMc5OsrXy5qL/cBwPh0c8Xo81L+D83Cg0wchczTO/hxS\nJWSCEfX/xj01pUokpEz43KJiHUuezyVkYDWzhHp5HRLxtV1up8hZahVC99wuj/K9Z4j9GDULH1pm\n2fIa9NYlxocGrqWG7RoDx3CGOo07UsIStfBanMcRpP0eLqFzPJ+2RxvDz82ba0gp/DzWHUQyYiaV\nLeE8YnnFesdVegiYqNDRXgbUI6shnZR0i8ZUuxdbTH7pGOsKFl5D06xCdkXIZegTNdr48THH3Cjz\n1S0TKeKwTMgICZ9lQ6mjt2EcZKLhfvJ1nkeo6zZM36N0l0ke75RuBact2lofEl5iuUud+y/vcXSO\nUvLDsgi4dIsgt+L+wsFZQLJ2jM3Or9+dZSY95H8mCeWSD7p26wbjNs6pwLILytYdknl2+H7kY+vg\nTiwSZXocp4+JnW+HIlNCCCGEEDPQZEoIIYQQYgZXKvOFZGxcZU/JBGG51lgvDSFzlvlCOJlhXIb0\nevyBibjWCG+e99nNdP2B7FBgaHR1hoSMFt0EdAZ2+HCe0xkS952eUQKiIwZJ0Ji4ErHrsB2cZ5CP\nmJTuEsLPLSSvVUeZEpIcary1Leo58boqymj5+CtITbyuawuGf/P+I9rK4ggyRM8kbHCI1TH5JZPI\ntpBXGen2UO8RiWYZ6t5T84xJ5RzPL9SZNCZChSTO2o3pcn7/LCrItswPu0RnQ2Neot2VI/VcXM8a\nkg6cgAu09yXuY4PtBbZr9FNKinRqhhqaZpZ82oVX0H3FhLx45twu8d4lau2dQ8egU7NEUkFH+29Q\nF7KAtFdUl9E30X7xumPgpNsx7EPTNO4Vr6uEZE+HGGXd60eUl7i8A1IjPquCXEi34O45tStKOEgK\nSxmONevQdtg2mSi5hPvP6fYMCTyZLDhNbg976gPOZYD0RhlqwBhchLEpv5djHpfEDExgSiccpTZI\n/yHRMr9PQp3c/Jz5fV2Uccyq+eBxqKaJUv3F56EdFs4MrqybiU0k51y309Ihr3MNZzJr4I53WW1R\nkSkhhBBCiBloMiWEEEIIMYMrlfkYfg6epFBrj5IXXGuIoFJGK0PiMnwWagaddXST5H0aJgtlArDT\nLBHQSbZT/suqPQlGR9bOw3Fb1DDrjQ7GaUcM7XBM7Ml6UCXqGfHa6G7w4fBSQoIk1fXZbbJmYkeE\nZxkapirUh0SoeAZwj4TwNF5nMlY8Suvxeu+Uf+DsKGPTZ+I2KkF0m7CO1LqFlMvEgJDnBrSPNWWo\ncTqxZcP6dcEBk7er4nK6bFnkczpCGcEmIZkiZKsK7bFCW2Y9N8owHergDdBn6a6l5OWQSPsgW+H5\nI+LPGpibv7Gv4W+0mKIhjviMFvX71nQGlRw8IGPhc/fV31xif4fM5354aahHX+tbyiKsgTo99rEf\nhW1Ie6XzmeWdmgWvl3XTML6z3UDaq0Pi0DhejfhbARcik/yGRM4YMFZMnIrXY63BadmONetaSHhM\nrsu2uVsf8lC0N/MSFNbsbFjLjjUY6Xilcy4kWMVzoCtwhX6K9/a8j/isaszPoykp+U6768zMSvbH\nIHNDbuPSH7joU8/v3DyO1JCGmfB3oFSJY3JsGs5zf+fcYizvLtakyJQQQgghxAw0mRJCCCGEmMEV\nu/lYJwgnwRpQlF8gmTilAcp5PcOP+XWG2wefnjOyphxDtANcSA2TiO4kv6TLYF3gPXSoIYQ+4tqq\nI1ynU+acliTWdLdhF4ZTmcyT97ecNknMooDrwW06qWRIQNoxEeQ59p+u8VZSs2RiQLiKgoAHdxLl\nogoJIhOkoFUfHyaT21VFDp93DO+vIQXhWOeQNteU/AwJIuG8YY0/D7IgamEh5E1H6Z6mPJsHrgVr\nZN5E+LyvIdPDAdUgUavhXpxT2vTpfhScnegflFsoWd88zzJESBy7U2vNQ/JfyFI15QfW0MznegqZ\nrx3z542QrvoS9wIdLAWZCA6rgq0VySZ3s8ceAmeHp3QOKRvtlzXREhJYcvlBD1m7KlErEs+sqajf\n5/bLZ8M+XoearHTQRrmMDlYeq4Yjd71GLdaWshJrEzLxJqU6tINQoxHO75ZyEY+Oe2qX8CzN7OYj\n77vYrrAU4P9v786WG0fSJQFj5SIp85ye93/HGauqFBdsc9E2FV/QoNNZRkk3436FYkEkEBuQv4e7\nd/P57+NRY9tu/z4r0Oc+Q3q+Z6pyRjU19nxpc/eZmIn6MXwGd83+c3DYpDDpT54pHXOcR0FlyHo1\na8+tA1CYZvq+TzHtDIIgCIIg+DbkZSoIgiAIguAJfCvN13+QE1Rlx5HhJT9lObXyoNScU2WQsYwR\nHQAAIABJREFUNAGZX5aJYSTq/KBWuoFsp4eSqeXe+738x1HVACVk72E8Ipmq1AfQgq206D6V0KKe\naj8oM6/TF6hMqjxBrn+RVtg3wny/agBXaJTD0f7D8NAsQlRFg2MIuqzHtFPllDRfV3s8NpsZZqrE\nNAyk3a+YAf55QfGlCkWmsi0l+Q4a0fE7cc8L+Y4jKrLD4Wv+/XM+ajwKTcAcvGqGeIUCYF6rGEII\n2GxQQMRiNTf6RHqtqZSg0C0Y7JmB+ch/jmT+bdDlKr0qdSaqn+sGpWMOmWaDnWaA5XhgO0IP3dwz\nDkdUb1/RnxuKLwVJI9c2YLqqR2a77s9BKRib4eh2Ddpz5N/pI2uU2ZWnKmOVdW+t20RVt6o654vr\nuuuOSsVaQe6xWZls0VBBXtFCfhFr0/oBpfYkzObruZ9ZxbNbZdyyUD1DC6TOTwcGwLr/t9LFLfNp\n1LzX7zyX9W55UGfON/oTle/gejHyHOGZMjH/V01VVSSyLWS7QdOj2jMqtof+azH8XG61Sfd/QipT\nQRAEQRAETyAvU0EQBEEQBE/gW2m+auc+5cFV5VbvOagGKOP1qlWkRlRuyNqZA8j1VJQEaoWbqg9+\nax5qGm1F0bZRsr5C7a3UE1WfdNAQ0hgbGXNe91hRKZrsaRBark1l1Nz+M1XC70BFmo290V53eVTV\nXFAtNzPRjMtTCXajfWyT477D4Ea9uDNTjNP7rR76twsGk1A+7Vj+aCCnbr2i/uxUqmny6jhFDTVC\nqTEgL1Bng/0N73g8fo0x4NuLVAxU+I05goKvMjbtNFLlWEPK/aZofpE7drlahjcjzbyw8vn7pfzt\n7cEw8Xh+KT/NeFC5I12+YO56Xcr3Hl6gxlDgmrt3g6roNFU8oXg8SoF8Lc3X95o5Vsl7O0d1rmGP\nKmpk7B9ZHw/QzpzStCinDtLu3f4WDbPszL5rHukynhXNur+Vw6zMMwapG9d6u+1T0wNrpVsQtg+y\n9rrKlLlqgN3zn8V0KTTf8IEBaiNVhQpNn9mmk/KDtpulZwsO1VpbaLvKy5KuOkIjn05lDM6PGXfk\nVF4vGnPv5+5p1Gv5xzWiVY1vFid7LQbowjvmpBuqxYPK35l8z99AKlNBEARBEARPIC9TQRAEQRAE\nT+Bbab4qhk2TPVVZFT+3TwseDkUJZ9l+uanoUPG2r2ioqCdKgFIYPSZpbWWGV5eWDyey6lQlQQH0\nozQBJdRRtRH0zrZf0t0qxVzBUmUymWf2+WZy0nktpo1th3melXtVNfTlMpXjP36Vdnt9hRqALhrP\nmEuOpfSsqevh5bUcHyqpEr9bl/C7mfuBntvovxtjbcaQcTyjzruX37tN9odjnLFJHV7l0YJacMMs\nc92+hkr4+aPMqYnS+A2KeJ6g3Wkv6bI7yrb2sG/geoOS+POd0j6K2BYaedIwUfXfr1/l+FqX5Dvm\nrSq2yqAQ6kqaz+Ofp/8q38O60+177jabhpyoilo+H6TMxi+g+aCw2lVTXK+HOUWbDCiZX06sudyv\n6toDf2s+mkbM5qBpuFxRfrMU94PN4wd/pLLN7R5dpcz2fOk5xrjz9F7Wr2WSXmbNbd1GUMbZ0H3+\nOts0TdPcGdsa+Po8cVuEpqU+yw4OVChftmMczdlUnQdV/vZWKPQZRe2xymkko7OpsblFhGc207+a\ns+7IOPBOMGOw2bK+1EagrEHb/thxLJjROUfNFwRBEARB8H3Iy1QQBEEQBMET+N5svnWfolglq8wV\nokR3c8c9TM/hBNWjagcqzM9P0HGqRO58v5lMmmtuD3SZ6ryqXM899JOlcsrXVf4UBpWUNy0/Xu+a\nf2pwB31ieZdS6lcwQ4qnzLNaKgNPc+oovUKRtW253/dboW18zf/X+Y3vUTUJ1WRe2KGcL2UwQ9M1\nfe3aeXih7D1gEjf/4vNSbm8ZhD1l5dUx9eeffx8v9gftYlDdiMmjY2U8Yjr7Rf/+aRtpMuejPAG0\nB6aVVe4gbqgtjo4L4/0XKrz3+1/lby/kbN5Lu/z1V6F/NUacoWEqA8+maWbaqUfF9BOK4nhSXYvq\nB9XexFiYaYsBCm9AqXdEFXk8lfs/wgQzxZvz6YHS+gyoLoU70QtzY55Kz0kF3lCR9dzjBHW4mnf2\nUtbi+a755X7eaCW5Zh1rNTRuajXXCv1t/t8gDYciq/ptc/RYs24o+GZMITfobrd0qChWePhRDN6z\n8NFyZvCcoXNPbLs4VjSnuYg+vxh3076x6fm1/NYr690L6sfO7Socq6C9PWQtzrwHdNCTR+6hZx2V\nShylJ32f0Mi69bkDpQ43ryJzY2vCgWY5H9U2/mekMhUEQRAEQfAE8jIVBEEQBEHwBPIyFQRBEARB\n8AS+1xqBd7cWzrKD+3TP0AF7XfneSinL59oY9NoNuGeKAMYBV1fpbh2gfd+s9iQ1TXPAafeIdlh+\nfUHWOvjqCo+8sQ9gPOh0Dq/P+fPdPUo4TrMPQPnp+gVk/h2u+3bVDgFpPHsiWvStG8POPVOn08+/\nj7uutPWibUGrVQW8+lKOJ5y6DVkdkTH3j1tVKqeO0l6nl/K9vy7s72nKfpIb0mLHuPYRK/e/rriq\n69bO5bhfzrHffZH82ns2cFS3+tE9QJv7ApFEs9frekUUzfnbnbH5Wj5/Z9/in9fS1n+8l7auhjL7\nlqat3jOlzPrIDS3sh/zRlfn/Xz/KXqrTz/L54cy+Ku6/YV/OgMv+EdfzF/ZPnfn8xP6j8/Hz/z3r\nvsVt3R9HK5YfS5X6zd4l9oit7JMxSLkKhXA/kzYMXMNa7aks339g/+m4/g97bJC0O4fdfmXwumG4\n9n3H+ugeI4ZyZYUytD5byprlEP+abIKmeWG/0pEbHZhTC+kJDVYqVTKEeyFb25H9rIzr9YJLOHuY\n3ILr82rkme4epmoPV9PUNhZVyDTPBW6hZX/Xylq72vj+RDUmuQ5c+Q0q1zGfx1Gz9GUd+B2kMhUE\nQRAEQfAE8jIVBEEQBEHwBL6V5rtTZu2hpEZ0w9IeJz7HNLgqLW6VnBL6hJLhGcnu8VjK+S2l5Zbz\nK8dwaIW+rR1RLY/qBLxCNy5Kailrd7qpQ910OsNXQceU1rnuqr5N+Op0V+77FUHHOs6Wz73OZlNa\nWk66cD3dZn+XvtHlvoeGOI7lHMvKK+7cf/0BtfpT53zpwvrfEau0a8WKMtZ0p4d6/OvPQkNpW6G8\nt8eSY4Ce7FunIGV75op0SPtYMv8kGIirPL6isz6QDc+M/QV7hw3qcCLF+rLhTs73H/jd+b3QfNsL\nNETlAI178q2mslfWlwGJ9xE67+VfhVY+/3f5/Od/Fwd9nbx1Cm+1tOCaBsaYIcZHPj9hGdE/WHR8\nBlxDHb9ayhzpJ8yqm6H1fvncZaaSw0ODOnG0quBj5fMnBlQL3XN4CAwe+XGd9A1Db/mbGbqxnQ0A\nNp27HOqMPrCYHfndHrq7Dmgu37M1/0xK/7swNHhgjZgM+t5MKoA6O7qtpQyAyiaBPjkyxrUIun1g\nvSD9e6GtfRYtD0HHhgxfsD1p9UrftO4o133n2XF5h6o2YYOxer+WtbkaR4ZBc/7g+jrX23r+E1KZ\nCoIgCIIgeAJ5mQqCIAiCIHgC36vmM6SS8vDLWXoHam/Q+bnAwNED1JB8k+X5I995Rs2nKoNN/1Xw\npa7tB9UATdN0lJYnSpeq+U7c22RgpUG2s0oqSqg6oONQfRgsJ6N4JJR2qYJlP5/mk24yWFV6xf6Q\nGjgsqGF0D1d509juZZjOV9RAWAPPBGZO/BvhflBZuU9NNk3TzPz2hCPwn3+Vzy/vUAl3lSsoCXFN\nVpnacQ8Hxn5TUYdcEBeoo29N4XweBmi+DQ5kgKNZoKNXjnv7Afpogdo7QXmdO3kfaBXouBXn8TN0\nxohr+ctrWQduDyV55/DrudB2L7hrv76WteBEgPYJ3quvyv7Q01Apg1QoCsMNNZjO9ZVq6Qv+OWso\nr8N8hp46SFWpAqZvZtzNF4ORt9KeZtbeUQjqQt6h/jOQ/Mj2i7baWlHTQk6XSinNMLqREDGzxWHB\n0bxvHyW8/+/H9wNwVaYqFp1RLG9QhMv6RXo+1YaVQzvrHJ9f3gm3HkuCw4GxPzA31xMB3oa20w1/\nLCXNYWJcvOAeXymZdTBfawr+dinX9H/+d/lex4Yh01LDVylCgs5X5poqT8ewdvUt8/TtzHYRnqHT\ntVCQv4NUpoIgCIIgCJ5AXqaCIAiCIAiewLfSfFJSPaXfnne6Acqog+ZT5daPlCsP+1RgX9Ekhp4O\nu8cbyb0wHs3C58exbi7VfDNlwx4nO0NEZ8r7DWXJ+5XyKLSKZp4D1zpV3oEYeKoA47qn++fTfKpq\nFsryE3RZZ7v7x5SPpbykVKdboXYuUqIYO46U7Q+o4o6UsK9/qExT/VOX5Cfa7g4deMEM7/KH9AE0\nDyqe8aghJ7QwKbOqFg2DXqpGQr3JONseSuafha5xrGG4SJt1/LaKxA51ac8snFAYvULPSe29/Cy0\nwnxBYXMsffCv7QfnF2ro7Wehm+5zPcYNuO00iYXCHQ2T5ngw+BcV1/2XNL1tUT4+nfitxrmJ8kiv\nwS/g+WTJ3BLQGpAOHT230OtLmXedAbBc5sJ3zgaJS6mwRUEKZmMtaqHFOiie7ZGDZ8FbpnJ9m9Q8\n652U1x3jSWkkKakOmtpxsKIWnjXgZRho8LwuD9f9SThDw13uhXraoP8W6XjWS4Obh0s5HlmDNFK9\nX8r3j7TLnblv8Pr5hVB5VOwbW2uW7WOa7xdK6P6kuauqzXJN94rOpSPWfcNYw7pbHuwH5vgBM2fd\nQvvHcfgfkMpUEARBEATBE8jLVBAEQRAEwRP4ZpqvQBrqDnXTD9AN0CQDRp29uX4qCCi9t1UJv5Tx\njub3oYyaKR/6hlllBz2U/VQZ9I1laq4DuYuqFpV6rXSjihBKjpqQms90u+1f98b3L8vnGwNK80kr\nWDIe6APLquuCegQlze2mogyKDLph4/tvV/lYSr7QArdeo1Rz8+r7sT/uZD799V5KzNf3mfOhCeby\nZWfHV6cbInSL45d+HSVDoQVbqYQHpdNnYV1VKJXPparsK6lAFagaWC5QhDN/22FgqgHvHRO+F0S6\nI6qv8w/UYOcyjlRY/ft+GP9Qssv1g3nu9ak+o+3fN1U/5d7OrANm7fWMvW0udIMUoaa1n4U733/A\n7Xhg3MlyS4tt0GgDJ42YtE43qDPoJdeotV4U/j7spKPwQFa9NV9rc+QFisl56npfKemcIvSfbJPn\nayK8sF1AQ0rp+Jnj27382GX6/HW2aZrmyFaW+8BWA661RbU8sU1Beu6q4o01Fea7OdI/M1stvLMB\nM+3DEVrwdN49f3p4/vSMyZlnf2ugpv0Mhe+4upPZuWnOyraIyrx6Ktf6hmpRpfERZd/5VLYR/A5S\nmQqCIAiCIHgCeZkKgiAIgiB4At9K890ouZ3mUqIfpW5QHGjy2Z5L+fGkmWdHaZDzh1EKzvI22WkY\n1GnHqU+fOXjdQy6aOVYrpf4ZpcxKzVm13VpdB1TPqLoN+g/TThUxdcYfNASlbjOWPgtmGGlsONAO\nNldl8indqQoPhYnKEJVmPfTKRIndcrHl6QM0kte2PqjizHz6hRncVSUkKsF+LCXtsVdRav9BBXKf\nm9Vs6KUjZpEtf7twPAxfk/8l7zNP+5SJeV7Sf/bJ0qiM0sAUc1Ip+AMqVb7zfCwKvsML1Clqydcf\npQw/jjVvq+pnuqoMYj5O0sca9XKfZnPe2RYATXLUwNSxyrH0Vq9i6Av+OXvDUPSoMtMsUsxir/R3\ny/aLnjZdNun1skbfUMs51+rsS9ZD+n5h3Zf6ftyWcIWGVGEnXapJ6MFMV6nHSfUf6l3pQubjxly7\nqvC9l3u7sKXg1+3z19mmaZpX6LNpLG3xLv2pmalbXzTClNqVVlWZLQVnNp/rpf0GbX6kjW5u45lq\nQ13NdqWeG7YaLPyNmY+q+i+o+VbeLVSDtoy9StVv0KjZhBibHtt/9nqUylQQBEEQBMETyMtUEARB\nEATBE/hWmm+inHqnhDiaDUUpsqN8vhw4h5LjQulWJdmBbK8ODs/zB8qBR7PToP8m1Q0PSippgq7f\np2I0XLxQTrXM7DkVHVRRY5S0130TTlVYy6oCbPf0p2DJWKrRPLoZhYVUVQctNkgjrdIQZh1iothA\nzVQcFDltqIGk71r+9v0X6qqmqaQ+d0rGHSVgFU2VwyaqUO/zMFDOHlR7Qg9XhrWFnlBF1las29fk\nf3WVag/ahzbuqnw5TC576ABVdSimzBTse7+T+QuntqwYDKpasuTPOX1tC9uM0lu9CjApNqihg8qt\nfWXn6xEDT+hCGcZWg1kVpkrJUH+u98//9+xd81vWgQkFqsaxp/Xn38fdQj9BZWoKqVLYtXhVlc3a\nVW2P6KUOoZSgDqsM06Zp7vSZa7BbDVz8bsjTOrc+aLy57dNis+s9KrJ3cvBuqPkuUKqX+9eo+d7I\nk51eodS3ss7dMDBtoSrNaJ2kc5kvS+Nzlrnm1hWpVi9O1biZiJz0aMLqe4CqaE04fXaM/L003+zj\nWGV+9ePl+Afmp+b79tDfI+eozP0dpDIVBEEQBEHwBPIyFQRBEARB8AS+lebrUENJb0hJqbhqH0r3\nf/8t5b1+0MzTDLNm91iVj+afUn6yR62Jf8sDxQJd01FmXCmE+vddVe7cL3ebmfURLaqyprq+bf8e\nmna/HZ+BZmgt1zPwW7NlfM08GQca0s2zWUsN59OeGCeagTjTyRPmdNK6M6Xwhyi3qm+GnhKw9FRn\nhpO0EP8m6fYpP81Gj2RbqQTsnR+V+SkKufFr1Hwbbbaar8j40nj1jGGmSqwNWnXVCBMqcIAuVbHL\n1G82+vzI3zZ8Z3MrqsuH9Md6HFaqH++NeQQ9x083YyclQc5Zq8LUbE0GlrmGUi8VjfX5eW6q887Q\nNjcolQPHLeO9WqG4x22TXjLjjznF563j17WOtV6e5nrdN43995extkLfzrZ7ZebJOTcUfPYHc61h\nO8nEmJjp+zvXMDGvYfmarf+aufnygjnttP9MsG+v3P+V8X6bNaxl24x5mmwhGdiy0ahYdvsNfb74\nfFNk/uCQbO7ebXJclXNY8prZeerDnO0xa6VCZetEp/q30KUvr5h2ohY2d/AQmi8IgiAIguD7kJep\nIAiCIAiCJ/DN2Xz7xpYL1dHhAxpjM2OpKlFDmYyqO8phle3E8UB2ltXndd0vgS4PsrgOZcqqGgzD\nsapsfLeUXfFw5XuafWqsUhK2GmNiKsrnbVUCbz4dKnQ2Sv22w+GAOq2X8oIaWFShqAosJdnBrEOG\n7ADN11LCnjoN6VTncP29Nq21MkiDUdV8L+diElnlc02OLweSqrV9+rq3L+mzAXPKytT1i0w7u4qi\nkfKyZA4lx7iWAvKcsZHaXXePNS311myvsVIX0r6abj6oHFXUjkiEB5R9tRJYSs61pnxnqyEn1GNb\nUaRQims59jvXWdrj8yl4lYawXM3lbiZg+fxAPmCHmeesIrgyyCx/K+2+Qjupbm41X2ZtldbVJ7aW\ni9UZn64RExNaurgyLGaeTvJINMDmY4OLWph3M2a8d55FmlNOXyO0bY6q0OjQ82tRZN47lHS9163J\nJYo82tjn3ZXvb1Wcs5b30P0N4/pw1oxzX6XXNE2zoPitsmjBVm0R+UBdrLIX6lHD7iNj50Qe30g+\naI/ZrFmhJ8xFfwepTAVBEARBEDyBvEwFQRAEQRA8gW+l+TTvWq3FavxF2bRBHVHTJKr2KPtR0tMk\nsKuyejhWjWcm0bpPE2nm1zRN00IfdJWCz3vbN7trquv4gNpbbBdoRBRT9/t+qVulogaLn4WK5uO3\njuRidVVeYSkxVyyHx6sGc6g8PIc26SkFj4yVt5eS6zaiwBuuF26g7svBvEBq4HWm4IFzuAVoKGm4\nA8oQy+RdRdtRepbirjxBMdLramXMZ6GllN4xTlVAri0mjmYW0s/9Js1HHp3zgLJ/JaKlzxu+f4VK\nWqTNmRNtX7eLbabSp63WGulJaCn6sFqPoPN0F/Y7ne+rBqb8s3Uxqmz7/CX4F8o4VYQd7Wj24wYt\n0jW2mwak/EClJqY9nRPOIXk7VX64nTontq2mfqTRRyimyoST82d++8b6WEdOQjUxp2aOpfyufOc7\nC9I7fXlbvmZuvv0opqrmLs4tqtiR7NaurHMXshNfUa2pNPYZt3ncOCdUrBY85ij+fT7j3T5rmvpZ\naz9cb9yD22sch/T0OOw/d1QdqwqUnjy/lm0kb28c/yjU6RuKv99BKlNBEARBEARPIC9TQRAEQRAE\nT+B7TTul1T5Qm5mlNEjzadxGeX+mjDtTKu5UFR39HqUopZQoFUYkVXOHepB6evz7rtvPRrIAbRl8\nWVTW8BvQCjdoKRUXqpAmMpNmPrfgbFt/FjSe3CjbauaoGV4/cUy7WdCfpWOkcqGgNkrpC9/fVqyx\ndC/mbCfoogcqwRbqLVGj7nBsNgcoEwIGpT+l/IYRY0TUNuOoGZ5GtuSRSWd9jZivuVNin+FDpru0\n1b4Z7QonudF486Yqlu+R2mPy32+q4vitU+nD+yIFv59B1jS1uqeKcFQNpB8vf3vl/AmKSeqqMjZ1\ny4LXsUqf7CtzVb19FjT1vdGOE8v9nf7bPrjm5e7njnF+zFunrZpK1asCV8mmilWup6sfS66VKtWc\ntBOL9h2V55Vb0OSy2mUC1bRyHWtfPr9Bi72zll1VC65fQ/O9vpZtC9J8a0c2n/RpX54JL67HlVK8\nfEqzVM9ct4rMUv/SqDx/Tiee0Zp5PqjJe/rQnu51UubvfX4fVN65/rdSwaWvXs5lfX15KxTej5+F\nOv1f/yrt+wMF3+vpny22qUwFQRAEQRA8gbxMBUEQBEEQPIFvpfk0XLO8r3rK7KEVX0XPt6Rv1l5V\nSlcNRJnYMvO2aaIJdQZ1qFquUvY0TXPHBM3ad19xTlAdrTQTNCQqLtuiMhXk82ny/s2h04kNWq37\n/G6WIlmhKrwvS/dmHvn5tTIDhEatcp72x42/NaNwnKRXqnZW4VkrHLfKoK6cdzgVpYfl6tFrqpRn\nXB/014Hy+ZHvrMxV233eqaKal9oA77NQKWYqOgsFH9eh2eh92S/pm9vVoLwZj6pkMEC8qPJTsQvF\nrVqOv5WmbJqanpWeU53YS0lWFLlmvNyC1zS7Rph5Bn2PylP1Z4fZ7PYFjrqtYxOq5s6a8JfSNuSF\n21yoo3Uqxx00ilTpPGlSWtpkREZ1YD0cVRcuUocfU2SbSu5Zh01yTN2agVy4MttsHEf8QKsJpWt0\n+a0717CqvmY8VsbKn4iXl2IWfIV6vUD5jUfotvP+fZozKsWqmakemubkTm6tQcF3POwr6jTavHf1\n9piBeXeEwjsdMRvF+Fql7QnqjSWlyuxTzfemau+FbD62Drg15RUj1B+c/ztIZSoIgiAIguAJ5GUq\nCIIgCILgCXwvzUfZsGI0LNdCK1yu5oJhIIZZ40oO1cw5V77/BgVwoLy3URo8Qu1Ic2iQOT/QfBqW\nqcTyFdXML8+/a5KI+sKGmavcJ/KTrl7TvkJFg9H2C9R8lbHlvv9qM9F2UiqKhyYztcxzUmJi1hb9\nvUKXdKj2/IFVJaB5fG1dkldttkDzTJT6bV+NIDsovAGaYECp5znSU327r+CrXO8YUF+hzPz3dZTj\nrcq/MoOPeXF9L8dQRtUMkQrWqBJT3Mqs0fBE7lPVnvOsSrjbHpS2k/fwAW0p08U9DCrGpAgrOa5m\nvlCk5gCq+GzdBlC+5is8WBcGqpT3r2vphOtGh9A5C9Rey+d963yUvvQYE1SpHNr5ANXYmZP4P1Bk\nqr+ct66tzselMj4ufzpB/9mVrtcVxd26/qI65Tuvk8+uh1DBT0KlcIeqk8p+hapyDdY4WDX63WeL\nFB7rq4ash0qN6haJfUV805T1eG3qvq1zUPkmzbXpZyk81fiDanGz+Tj2uf5CxqH03wl68sia/VFO\n8EdIZSoIgiAIguAJ5GUqCIIgCILgCXyvaSdlQHfcm211n/eNJ+sIN8qPI3TTByXzO6XbDpWAKqEj\n+VQqbzTte6xEVxSSlCGlVVVSN9R/ywf5bxVlwG9JhZphpMmneYeqyioK8pPQV7mJqEqQWFhil57S\nAE7DR0U18kVLlQ9XTlpUh6q06ulvKs9rZdhYD5bxiIqHPpgoe9duharTitqmRy2q2dxQSU+g7VQ8\ntlKKqgvJTvuCnMWmqemmrsq/2j9/xjxzhG4daXDpQidwS+f6u7KwFeUp3XCEIqAP71Pdn9K2UpWD\n18GPIwZrGiiwhWut7wfV6rA/rrrBcejnjPkv+Ofs5Vqouol2WSq/Symy2+6xlJ9jQp9Rp4TUvxN4\nNFsPOlX6roo3fFhn2670jnRplRtZbcHwnH2qTmV1i8HzxnXXprMozaD+FVBXNPAn4gg99eJ6T+MP\nPL9ObGXx/m+oTi+a9Fbmt1Jqqlptow/ybd2O4CB5GORScipba5qP85l3Pmel/0boz/4D+k867w3V\nnmq+A2t2RS//BlKZCoIgCIIgeAJ5mQqCIAiCIHgC30rzWQat1CFVNhQlPcrkUnvmdvV9KVd2NZdQ\nPr9qBkjpEipBQ0fLmEuVt1S/ey6TxqDl+HAgt27dV/14fVuVmaT6jzaibHqFLpyqa1DRQjn4C4wB\nmw/aWlWOGXTSlI3ZTGMpvZrzpOSphVJryMJqzfmS/pIiqn4Xs8QHhYll/378oKzcWlYvvz1vjhGU\nN1CSH5WM1w/o3r4yrYRG/QID1qapc7UmaQ/MF7fN4/K3FbnB/LJZnAcd36kCSINBjUrnKhNQ41AU\nY0Pdn+1HuY3DPk3KLVdjWBWqmZKVqtIhJu1VUWNkNkLJDKwVn4X5jvEm6+zqJaO8Wz6g+ebZtXXf\njLdWY0F3cj0dNF1/228358HjemV/VP+rMn7ep6GWyhTYNYscueaDNZ5zOtaptlLmqi5gRQh9AAAB\nXUlEQVT9mmy+tx9vfx8zBZvDuVzTK7lzmklXNKeUn8+NDyhWDWVVFDpnzSL1cw0/24f8SVup7k6N\nYQuq3EbOMVNSlaNbJ6QqNVp2K46Kx0qR+A+fm6lMBUEQBEEQPIG8TAVBEARBEDyB9iuyoYIgCIIg\nCP5/QSpTQRAEQRAETyAvU0EQBEEQBE8gL1NBEARBEARPIC9TQRAEQRAETyAvU0EQBEEQBE8gL1NB\nEARBEARPIC9TQRAEQRAETyAvU0EQBEEQBE8gL1NBEARBEARPIC9TQRAEQRAETyAvU0EQBEEQBE8g\nL1NBEARBEARPIC9TQRAEQRAETyAvU0EQBEEQBE8gL1NBEARBEARPIC9TQRAEQRAETyAvU0EQBEEQ\nBE8gL1NBEARBEARPIC9TQRAEQRAETyAvU0EQBEEQBE8gL1NBEARBEARPIC9TQRAEQRAETyAvU0EQ\nBEEQBE/g/wLf1Ip6IDk7/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11973f860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
